######################################################################
## mgarch class for mixture density of the GARCH model
######################################################################

library(inline)
library(compiler)
library(tseries)
library(fGarch)
source("~/dropbox/Uni Work/Masters Thesis/Codes/Constraint Newton Method/cnm.R")
source("~/dropbox/Uni Work/Masters Thesis/Codes/Constraint Newton Method/dden.R")

## Load the R history from Shumway and Stoffer
load("~/Dropbox/Uni Work/Masters Thesis/Codes/State Space Model/tsa3.rda")


## Estimation for Garch(1, 1) only, we are ignoring the mean (mu) at
## the moment but will be one thing that will be implemented

## TODO:
# (1) To include the mean in the function.

# (2) Obtain the correct inital values for both a_t and sigma_t for
# thecalculation of both sigma_t and the db1


logd.mgarch <- function(x, beta, pt, which, eps = 1e-10){
    ## Initialise parameters
    T <- length(x)
    lpt <- length(pt)
    dl <- vector("list", 4)
    names(dl) = c("ld", "db1", "dt1", "dt2")
    ## Initiate the conditional variance
    sigma <- double()
    #sigma[1] <- x[1]^2 ## Need to double check this
    fg <- fgarch(data = x)
    #sigma[1] <- nyse.fgarch@sigma.t[1]^2
    #for(i in 2:T){
    #    sigma[i] <- beta[1] +
    #        beta[2] * x[i - 1]^2 + beta[3] * sigma[i - 1]
    #}
    gamma <- (x - coef(fg)[1])/fg@sigma.t
    ## Calculate the log density
    if(which[1] == 1){
        dl$ld <- c()
        ## This section can be improved
        for(i in 1:lpt){
        dl$ld <- cbind(dl$ld,
                       ifelse(!is.null(pt[i]),
                              dnorm(gamma, 0, pt[i], log = TRUE),
                              0))
    }
    }
    dl$db1
    ## Check this
    ## (1) Check whether the lag(bx, bsigma) are specified correctly
    ## (2) Check whether the equation are solved correctly
    bx <- c(x[1], x[-T])
    bsigma <- c(sigma[1], sigma[-T])
    dl$db1 <- array(0, dim = c(T, lpt, 2))
    if(which[2] == 1){
        dl$db1[,, 1] <- matrix(rep((bx * (x^2 - 1))/
                                          (2 * sigma^2), lpt), nc = lpt)
        dl$db1[,, 1] <- matrix(rep((bsigma * (x^2 - 1))/
                                          (2 * sigma^2), lpt), nc = lpt)
    }
    ## Calculate the first order derivative with respect to theta
    dl$dt1 <- double()
    if(which[3] == 1){
        for(j in 1:lpt){
            dl$dt1 <- cbind(dl$dt1,
                            (gamma^2 - 2 *pt[j])/(2 * pt[j]^2))
        }
    }
    ## Calculate the second order derivative with respect to theta
    dl$dt2 <- double()
    if(which[4] == 1){
        for(k in 1:lpt){
            dl$dt2 <- cbind(dl$dt2,
                            (pt[k] - 2 * gamma^2)/(2 * pt[k]^3))
        }
    }
    dl
}

## New logd.mgarch based on fgarch
logd.mgarch <- function(x, beta, pt, which){
    fg <- garchFit(data = as.numeric(x))
    gammat <- (x - coef(fg)[1])/fg@sigma.t
    dl <- vector("list", length = 4)
    names(dl) <- c("ld", "db1", "dt1", "dt2")
    if(which[1] == 1){
        dl$ld = -0.5 *
            sweep(outer(gammat^2, 1/pt, "*"), 2,
                  log(2 * pi) + log(pt), "+")
    }
    ## Check this, now there are no beta to estimate
    if(which[2] == 1){
    }
    if(which[3] == 1){
        dl$dt1 = sweep(outer(gammat^2, 1/(2 * pt^2), "*"), 2, 1/pt, "-")
    }
    if(which[4] == 1){
        dl$dt2 = sweep(outer(gammat^2, 1/(pt^3), "*"), 2, 1/(2 * pt^2), "-")
    }
    dl
}


## Rewrite the log-density and the key function as revised on 27th
## July 2011
logd.mgarch <- function(xt, beta, pt, which){
    T <- length(xt)
    lpt <- length(pt)
    lb <- length(beta)
    dl <- vector("list", length = 5)
    names(dl) <- c("ld", "db1", "dt1", "dt2", "sigma.t")
    sigma.t <- double() ## The conditional standard deviation
    sigma.t[1] <- var(xt) ## sample variance suggested by QRM
    for(i in 2:T){
        sigma.t[i] <- beta[1] + beta[2] * sigma.t[i - 1] +
            beta[3] * xt[i - 1]^2
    }
    sigma.t <- sqrt(sigma.t)
    dl$sigma.t <- sigma.t
    if(which[1] == 1){
        dl$ld <- -0.5 * (log(2 * pi) +
                         sweep(sweep(outer(xt^2/sigma.t^2, 1/pt^2, "*"),
                             2, log(pt^2), "+"), 1, log(sigma.t^2), "+"))
    }
    ## Will need to check how to obtain the initial values of x_0 and
    ## sigma.t_0
    lxt <- c(mean(xt), xt[-T])
    lsigma.t <- c((sigma.t[1] - beta[1] - beta[3] * mean(xt))/beta[2],
                sigma.t[-T])
    dldsigma <- outer(xt^2/sigma.t^3, 1/pt^2, "*") - 1/(2 * pt^2)
    if(which[2] == 1){
        dl$db1 <- sweep(array(dldsigma, dim = c(T, lpt, lb)),
                        c(1, 3), c(rep(1, T), lsigma.t^2, lxt^2), "*")
    }
#    if(which[2] == 1){
#        dl$db1 <- sweep(array(outer(-xt^2, pt, "+")/
#                        outer(-sigma.t^2, 2 * pt, "+"),
#                        dim = c(T, lpt, lb)),
#                        c(1, 3), c(rep(1, T), lsigma.t^2, lxt^2), "*")
#    }
#    dldsigma <- outer(xt^2/sigma.t^3, 1/pt^2, "*") - 1/(2 * pt^2)
#    if(which[2] == 1){
#        dl$db1 <- sweep(array(dldsigma, dim = c(T, lpt, lb)), c(1, 3),
#                          c(cumsum(c(1, cumprod(rep(beta[1], T - 1)))),
#                                  ## dsigmada0
#                          beta[1] * cumsum(c(0, 1:(T-1) *
#                                       cumprod(c(1, rep(beta[2], T - 2))))) +
#                           1:T * c(1, cumprod(rep(beta[2], T - 1))) *
#                            sigma.t[1] + beta[3] *
#                           cumsum(c(0, 1:(T-1) *
#                                    cumprod(c(1, rep(beta[2], T - 2))))) * lxt,
#                                  ## dsigmada1
#                          c(1, cumsum(cumprod(rep(beta[3], T - 1)))) * lxt^2),
#                                  ## dsigmadb1
#                          "*")
#   }
    if(which[3] == 1){
        dl$dt1 <- sweep(outer(xt^2/(2 * sigma.t^2), 1/(pt^2), "*"),
                        2, -1/(2 * pt), "+")
    }
    if(which[4] == 1){
        dl$dt2 <- sweep(outer(xt^2/sigma.t^2, 1/(pt^3), "*"),
                        2, -1/(2 * pt^2), "+")
    }
    dl
}


## Current working version
## Rewrite the log-density and the key function as revised on 27th
## July 2011
logd.mgarch <- function(xt, beta, pt, which){
    T <- length(xt)
    lpt <- length(pt)
    lb <- length(beta)
    dl <- vector("list", length = 5)
    names(dl) <- c("ld", "db1", "dt1", "dt2", "sigma.t")
    sigma.t <- double() ## The conditional standard deviation
    sigma.t[1] <- var(xt) ## sample variance suggested by QRM
    for(i in 2:T){
        sigma.t[i] <- beta[1] + beta[2] * sigma.t[i - 1] +
            beta[3] * xt[i - 1]^2
    }
    #print(beta)
    #plot(sqrt(sigma.t), type = "l")
    #lines(fg@sigma.t, col = "red", lty = 2)
    sigma.t <- sqrt(sigma.t)
    dl$sigma.t <- sigma.t
    if(which[1] == 1){
        dl$ld <- -0.5 * (log(2 * pi) +
                         sweep(sweep(outer(xt^2/sigma.t^2, 1/pt^2, "*"),
                             2, log(pt^2), "+"), 1, log(sigma.t^2), "+"))
    }
    lxt <- c(mean(xt), xt[-T])
    lsigma.t <- c(beta[1]/(1 + beta[2]), sigma.t[-T])
    dldsigma <- outer(xt^2/sigma.t^3, 1/pt^2, "*") - 1/(sigma.t)
    if(which[2] == 1){
        dl$db1 <- sweep(array(dldsigma, dim = c(T, lpt, lb)),
                        c(1, 3), c(1/(2 * sigma.t),
                                   lsigma.t^2/(2 * sigma.t),
                                   lxt^2/(2 * sigma.t)), "*")
    }
    if(which[3] == 1){
        dl$dt1 <- outer(xt^2/sigma.t^2, 1/(pt^3), "*") - 1/pt
    }
    if(which[4] == 1){
        dl$dt2 <- outer((-3 * xt^2)/sigma.t^2, 1/(pt^4), "*") + 1/(pt^2)
    }
    dl
}




## Rewrite the log-density and the key function as revised on 26th
## Sept 2011.
logd.mgarch <- function(xt, beta, pt, which){
    T <- length(xt)
    lpt <- length(pt)
    lb <- length(beta)
    dl <- vector("list", length = 5)
    names(dl) <- c("ld", "db1", "dt1", "dt2", "sigma.t")
    sigma.t <- double(T) ## The conditional standard deviation
    sigma.t[1] <- beta[4] ## Let it be beta[4] for now
    for(i in 2:T){
        sigma.t[i] <- beta[1] + beta[2] * sigma.t[i - 1] +
            beta[3] * xt[i - 1]^2
    }

    sigma.t <- sqrt(sigma.t)
    dl$sigma.t <- sigma.t
    if(which[1] == 1){
        dl$ld <- -0.5 * (log(2 * pi) +
                         sweep(sweep(outer(xt^2/sigma.t^2, 1/pt^2, "*"),
                             2, log(pt^2), "+"), 1, log(sigma.t^2), "+"))
        # T * m matrix
    }
    if(which[2] == 1){

        dldsigma <- outer(xt^2/sigma.t^3, 1/pt^2, "*") - 1/(sigma.t)
        sig.vec <- c(1, sigma.t[-1])
        cp.alpha <- c(0, 1, cumprod(rep(beta[2], T - 2)))
        cp.beta <- double(T)
        cp.beta[1:2] <- 0
        for(t in 3:T){
            cp.beta[i] <- sum((1:(t - 2)) * beta[1]^(0:(t - 3)) *
                              rev(xt[1:(t - 2)]^2))
        }
        cp.beta <- cp.beta * beta[3]
        dsigmadalpha0 <- cp.alpha #1
        dsigmadalpha1 <-
            (beta[1] *
             c(0, 0, cumsum(c(1, cumprod(rep(beta[2], T - 3))) * 1:(T - 2)))) +
             c(0, 1:(T - 1) * c(1, cumprod(rep(beta[2], T - 2))) * beta[4]^2) +
             cp.beta #2
        ## thiseqn 3 is wrong
        #dsigmadbeta1 <- c(0, c(1, cumprod(rep(beta[2], T - 2))) * xt[-1]^2) #3

        cp.beta2 <- double(T)
        cp.beta2[1] <- 0
        for(t in 2:T){
            cp.beta2[i] <- sum(beta[1]^(0:(t - 2)) *
                              rev(xt[1:(t - 1)]^2))
        }
        dsigmadbeta1 <- cp.beta2 #3
        dsigmadsigma <- c(0, cumprod(rep(beta[1], T - 1))) * 2 * beta[4] #4

        dl$db1 <- sweep(array(dldsigma/sig.vec, dim = c(T, lpt, lb)),
                        c(1, 3),
                        c(dsigmadalpha0,
                        dsigmadalpha1,
                        dsigmadbeta1,
                        dsigmadsigma), "*")
    }

    if(which[3] == 1){
        dl$dt1 <- outer(xt^2/sigma.t^2, 1/(pt^3), "*") - 1/pt
        # T * m matrix
    }
    if(which[4] == 1){
        dl$dt2 <- outer((-3 * xt^2)/sigma.t^2, 1/(pt^4), "*") + 1/(pt^2)
    }
    dl
}

logd.mgarch <- cmpfun(logd.mgarch)


######################################################################
## Creating the test vectors
######################################################################

## Change the name of beta to param of something else to avoid
## ambiguity with the beta function

## Check that beta[4] = sigma not sigma^2
dldsigma <- outer(xt^2/sigma.t^3, 1/pt^2, "*") - 1/(sigma.t)
sig.vec <- c(1, sigma.t[-1]) ## DIV by zero cause problem! SOLVE!
cp.alpha <- c(0, cumsum(1, cumprod(rep(beta[2], T - 2))))
cp.beta <- double(T)
cp.beta[1:2] <- 0

for(t in 3:T){
    cp.beta[i] <- sum((1:(t - 2)) * beta[1]^(0:(t - 3)) *
                      rev(xt[1:(t - 2)]^2))
}
cp.beta <- cp.beta * beta[3]



dsigmadalpha0 <- cp.alpha/sig.vec #1
dsigmadalpha1 <- (beta[1] *
    c(0, 0, cumsum(cumprod(1, rep(beta[2], T - 3))) * 1:(T - 2)) +
    c(0, 1:(T - 1) * cumprod(c(1, rep(beta[2], T - 2))) * beta[4]^2) +
    c(0, 0, cp.beta))/sig.vec #2
dsigmadbeta1 <- c(0, cumprod(1, rep(beta[2]), T - 2) * xt[-1]^2)/sig.vec #3
dsigmadsigma <- c(0, cumprod(rep(beta[1], T - 1)))/sig.vec #4





## Revised 20th August 2011, new log density function with mu and
## sigma.t_0 included as part of beta. However, this appears to create
## identification problem.
logd.mgarch <- function(xt, beta, pt, which){
    T <- length(xt)
    lpt <- length(pt)
    lb <- length(beta)
    print(paste(T, lpt, lb))
    dl <- vector("list", length = 5)
    names(dl) <- c("ld", "db1", "dt1", "dt2", "sigma.t")
    sigma.t <- double() ## The conditional standard deviation
    sigma.t[1] <- beta[2] ## sample variance suggested by QRM
    for(i in 2:T){
        sigma.t[i] <- beta[3] +
            beta[4] * sigma.t[i - 1] + beta[5] * xt[i - 1]^2
    }
    sigma.t <- sqrt(sigma.t)
    dl$sigma.t <- sigma.t
    if(which[1] == 1){
        dl$ld <- -0.5 * (log(2 * pi) +
                         sweep(sweep(outer((xt - beta[1])^2/sigma.t^2,
                                           1/pt^2, "*"),
                                     2, log(pt), "+"),
                               1, log(sigma.t), "+"))
    }
    ## Will need to check how to obtain the initial values of x_0 and
    ## sigma_0
    lxt <- c(mean(xt), xt[-T])
    lsigma.t <- c((sigma.t[1] - beta[3] - beta[5] * mean(xt))/beta[4],
                sigma.t[-T])
    ## Partial derivative of ld w.r.t (a0, a1, b1, sigma0)
    dldsigma <- outer((xt - beta[1])^2/sigma.t, 1/pt^2, "*") - 1/(2 * pt^2)
    if(which[2] == 1){
        dl$db1 <- abind(array(outer((xt - beta[1])^2/sigma.t^2,
                                    1/pt^2, "*"), dim = c(T, lpt, 1)),
                        sweep(array(dldsigma, dim = c(T, lpt, lb - 1)), c(1, 3),
                        c(cumprod(rep(beta[4], T)),
                                  ## dsigmadsigma0
                          cumsum(c(1, cumprod(rep(beta[4], T - 1)))),
                                  ## dsigmada0
                          beta[3] * cumsum(c(0, 1:(T-1) *
                                       cumprod(c(1, rep(beta[4], T - 2))))) +
                           1:T * c(1, cumprod(rep(beta[3], T - 1))) * beta[2] +
                           beta[5] *
                           cumsum(c(0, 1:(T-1) *
                                    cumprod(c(1, rep(beta[4], T - 2))))) * lxt,
                                  ## dsigmada1
                          c(1, cumsum(cumprod(rep(beta[3], T - 1)))) * lxt^2),
                                  ## dsigmadb1
                          "*"))
#        dl$db1 <- sweep(array(outer((-xt^2, pt, "+")/
#                        outer(-sigma.t^2, 2 * pt, "+"),
#                        dim = c(T, lpt, lb)),
#                        c(1, 3), c(rep(1, T), lsigma.t^2, lxt^2), "*")
    }
    if(which[3] == 1){
        dl$dt1 <- sweep(outer((xt - beta[1])^2/sigma.t^2, 1/(pt^3), "*"),
                        2, -1/(2 * pt), "+")
    }
    if(which[4] == 1){
        dl$dt2 <- sweep(outer(3 * (xt - beta[1])^2/sigma.t^2, 1/(pt^4), "*"),
                        2, -1/(2 * pt^2), "+")
    }
    dl
}

## Remove sigma_0 from beta as it appears to create identification
## problem.
logd.mgarch <- function(xt, beta, pt, which){
    T <- length(xt)
    lpt <- length(pt)
    lb <- length(beta)
    dl <- vector("list", length = 5)
    names(dl) <- c("ld", "db1", "dt1", "dt2", "sigma.t")
    sigma.t <- double() ## The conditional standard deviation
    sigma.t[1] <- var(xt) ## sample variance suggested by QRM
    for(i in 2:T){
        sigma.t[i] <- beta[2] +
            beta[3] * sigma.t[i - 1] + beta[4] * xt[i - 1]^2
    }
    sigma.t <- sqrt(sigma.t)
    dl$sigma.t <- sigma.t
    if(which[1] == 1){
        dl$ld <- -0.5 * (log(2 * pi) +
                         sweep(sweep(outer((xt - beta[1])^2/sigma.t^2,
                                           1/pt^2, "*"),
                                     2, log(pt), "+"),
                               1, log(sigma.t), "+"))
    }
    ## Will need to check how to obtain the initial values of x_0 and
    ## sigma_0
    lxt <- c(mean(xt), xt[-T])
    lsigma.t <- c((sigma.t[1] - beta[3] - beta[5] * mean(xt))/beta[4],
                sigma.t[-T])
    ## Partial derivative of ld w.r.t (a0, a1, b1, sigma0)
    dldsigma <- outer((xt - beta[1])^2/sigma.t, 1/pt^2, "*") - 1/(2 * pt^2)
    if(which[2] == 1){
        dl$db1 <- abind(array(outer((xt - beta[1])^2/sigma.t^2,
                                    1/pt^2, "*"), dim = c(T, lpt, 1)),
                                  ## dldmu
                        sweep(array(dldsigma, dim = c(T, lpt, lb - 1)), c(1, 3),
                        c(cumsum(c(1, cumprod(rep(beta[4], T - 1)))),
                                  ## dsigmada0
                          beta[3] * cumsum(c(0, 1:(T-1) *
                                       cumprod(c(1, rep(beta[4], T - 2))))) +
                           1:T * c(1, cumprod(rep(beta[3], T - 1))) * sigma.t[1] +
                           beta[5] *
                           cumsum(c(0, 1:(T-1) *
                                    cumprod(c(1, rep(beta[4], T - 2))))) * lxt,
                                  ## dsigmada1
                          c(1, cumsum(cumprod(rep(beta[3], T - 1)))) * lxt^2),
                                  ## dsigmadb1
                          "*"))
#        dl$db1 <- sweep(array(outer((-xt^2, pt, "+")/
#                        outer(-sigma.t^2, 2 * pt, "+"),
#                        dim = c(T, lpt, lb)),
#                        c(1, 3), c(rep(1, T), lsigma.t^2, lxt^2), "*")
    }
    if(which[3] == 1){
        dl$dt1 <- sweep(outer((xt - beta[1])^2/sigma.t^2, 1/(pt^3), "*"),
                        2, -1/(2 * pt), "+")
    }
    if(which[4] == 1){
        dl$dt2 <- sweep(outer(3 * (xt - beta[1])^2/sigma.t^2, 1/(pt^4), "*"),
                        2, -1/(2 * pt^2), "+")
    }
    dl
}

## Test how much faster is vectorisation, too much...  Don't
## understand why the same coefficients would still result in
## numerical error
fg <- garchFit(data = nyse)

## Need to fix numerical error and check how the sigma.t is calculated
## in garchFit


nyse2 <- rep(nyse, 2)
T <- length(nyse2)
lsigma.t <- c()
lsigma.t[1] <- fg@sigma.t[1]^2
system.time(
for(i in 2:T){
    lsigma.t[i] <- coef(fg)[2] + coef(fg)[4] * lsigma.t[i - 1] +
        coef(fg)[3] * nyse2[i - 1]^2
}
)


vsigma.t <- c()
vsigma.t[1] <- fg@sigma.t[1]^2
system.time(
aprod <- t(outer((T-1):1, (T-2):0, "-")) - 1;
aprod <- coef(fg)[4]^aprod;
aprod[upper.tri(aprod)] <- 0;
vsigma.t <- c(vsigma.t[1],
              c(as.numeric(coef(fg)[2]) *
                cumsum(c(1, cumprod(rep(coef(fg)[4], T - 2)))) +
                cumprod(rep(coef(fg)[4], T - 1)) * vsigma.t[1] +
                        coef(fg)[3] * aprod %*% nyse2[-T]^2))
)



plot(lsigma.t, type = "l")
lines(vsigma.t, col = "red", lty = 2)

plot(lsigma.t - vsigma.t[-1])

head(lsigma.t)
head(vsigma.t)

## Working version
valid.mgarch <- function(x, beta, mix){
    beta[1] > 0 &&
    beta[2] >= 0 &&
    beta[3] >= 0 &&
    (beta[2] + beta[3] < 1) &&
    all(mix$pt > 0.1) &&
    all(mix$pr >= 0)
}

valid.snpmle <- function(x, beta, mix)
  valid(x, beta, mix) && all(mix$pr >= 0)

## Working version
initial.mgarch <- function(x, beta = NULL, mix = NULL, kmax = NULL){
    if(is.null(beta)){
        cgf <- coef(garchFit(data = as.numeric(x), trace = FALSE))
        beta <- c(cgf[2], cgf[4], cgf[3], var(x))
        mix <- dden(1, 1)
        list(beta = beta, mix = mix)
    }
}


## The range function, just use this for now
#range.mgarch <- function(x, beta) c(0.1, 5)

## Fit a garch
mnyse <- nyse
class(mnyse) <- "mgarch"
fg <- garchFit(data = as.numeric(mnyse))
inits <- initial.mgarch(mnyse)

testFit <- logd.mgarch(as.numeric(mnyse) - coef(fg)[1],
                       beta = inits$beta,
                       pt = c(1, 2), #inits$mix$pt,
                       which = c(1, 1, 1, 1))
str(testFit)

plot(testFit$sigma.t, type = "l")
lines(fg@sigma.t, col = "red", lty = 2)

testll <- apply(testFit$ld, 2, sum)
plot(testll, type = "l")
inits$mix$pt[which.max(testll)]


## Plot the derivatives
image(testFit$ld)
image(testFit$db1[,, 1])
image(testFit$db1[,, 2])
image(testFit$db1[,, 3])
image(testFit$db1[,, 4])

image(testFit$dt1)
image(testFit$dt2)

## This shows that the likelihood is higher at extreme points
plot(testFit$ld[, 1], type = "l")
lines(testFit$ld[, 100], col = "red", lty = 2)

## This shows that the function can be used to estimate the parameters
## of a normal GARCH model and thus showing whether the log density is
## specified correctly
check.ll <- function(beta, data){
    ll <- -sum(logd.mgarch(as.numeric(data) - coef(fg)[1], beta, pt = 1,
                       which = c(1, 0, 0, 0))$ld)
    ll
}
check.fit <- optim(inits$beta, check.ll, data = mnyse)

## This solution is different since the optimisation is unconstrained.
tt <- double()
tt[1] <- var(nyse)
for(i in 2:T){
    tt[i] <- check.fit$par[1] + check.fit$par[2] * tt[i - 1] +
        check.fit$par[3] * nyse[i - 1]^2
}


## Fit the mixture model
mymgarch <- cnmms(mnyse, plot = "gradient")

## new impact curve of nyse, see if you can draw the lower bound
plot(fg@residuals[-2000], fg@sigma.t[-1], xlab = "eps_t-1",
     ylab = "sigma_t", main = "The new impact curve of NYSE")


######################################################################
## Check whether the GARCH estimation is working properly
######################################################################

garch.ll <- function(beta, x){
    T <- length(x)
    sigma <- double()
    #sigma <- fg@sigma.t
    sigma[1] <- fg@sigma.t[1]^2 ## Need to double check this
    for(i in 2:T){
        sigma[i] <- beta[1] +
            beta[2] * x[i - 1]^2 + beta[3] * sigma[i - 1]
    }
    #ll = -sum(-1/2 * (log(sigma) + x^2/(2 * sigma)))
    ll = -sum(dnorm(x, 0, sqrt(sigma), log = TRUE))
    #list(ll, sigma)
    list(ll, sigma)
}



#fg <- garchFit(data = nyse)
fgcoef <- coef(fg)
plot(fg@sigma.t, type = "l")

mg <- garch.ll(c(fgcoef[2], fgcoef[3], fgcoef[4]), nyse)
plot(sqrt(mg[[2]]), type = "l")

## This shows that the sigma is estimated correctly, however can be
## improved
plot(fg@sigma.t, type = "l")
lines(sqrt(mg[[2]]), col = "red", lty = 2)

plot(fg@sigma.t - sqrt(mg[[2]]), type = "l")

fg@fit$llh
mg[[1]]
######################################################################
## The Log-likelihood and the conditional variance are very similar to
## those estimated. However, the estimation can still be improved.
######################################################################

######################################################################
## Rewrite the maxgrad function to fix the grid
######################################################################

maxgrad <- function(x, beta, dmix, ma, grid=100, tol=-Inf, maxit=100) {
    if(length(grid) == 1){
        ##rth <- range.mgarch(x, beta)
        grid <- seq(0.1, 20, length = grid)
    }
  np = length(grid)
  dg = grad(x, grid, beta, dmix, ma, order=1)$d1
  jmax = (1:(np-1))[dg[1:(np-1)] > 0 & dg[2:np] < 0]
  if( length(jmax) < 1 ) return
  pt = (grid[jmax] + grid[jmax+1]) * .5
  left = grid[jmax]
  right = grid[jmax+1]
  if(length(pt) != 0) {
    pt.old = left
    d1.old = grad(x, left, beta, dmix, ma, order=1)$d1
    d2 = rep(-1, length(pt))  # or d2 = rep(1, length(pt))
    for( i in 1:maxit ) {
      d1 = grad(x, pt, beta, dmix, ma, order=1)$d1
      d2t = (d1 - d1.old) / (pt - pt.old)
      jd = !is.na(d2t) & d2t < 0
      d2[jd] = d2t[jd]
      left[d1>0] = pt[d1>0]
      right[d1<0] = pt[d1<0]
      pt.old = pt
      d1.old = d1
      pt = pt - d1 / d2
      j = is.na(pt) | pt < left | pt > right
      pt[j] = (left[j] + right[j]) * .5
      # print(pt)
      if( max(abs(pt - pt.old)) <= 1e-14 * diff(range(grid))) break
    }
  }
  else i = 0
  # print(i)
  if(dg[np] >= 0) pt = c(grid[np], pt)
  if(dg[1] <= 0) pt = c(grid[1], pt)
  if(length(pt) == 0) stop("no new support point found") # should not happen
  g = grad(x, pt, beta, dmix, ma, order=0)$d0
  names(pt) = names(g) = NULL
  j = g >= tol
  list(pt=pt[j], grad=g[j], num.iterations=i)
}


plotgrad <- function(x, beta, mix, ma, len=500,
      xlab=expression(theta), ylab,
      cex=1, pch=1, order=0, lower, upper, ...) {
  if(missing(ylab)) {
    ylab = switch(order+1,
    expression(d(theta * "; " * G, beta)),
    expression(d[1](theta * "; " * G, beta)),
    expression(d[2](theta * "; " * G, beta))  )
  }
  if( missing(lower) || missing(upper) ) {
    rth = c(0, 20)
    if( missing(lower) ) lower = rth[1] # - .05 * diff(rth)
    if( missing(upper) ) upper = rth[2] # + .05 * diff(rth)
  }
  pt = seq(lower, upper, len=len)
  g = switch(order+1,
    grad(x, pt, beta, mix, ma, order=order)$d0,
    grad(x, pt, beta, mix, ma, order=order)$d1,
    grad(x, pt, beta, mix, ma, order=order)$d2)
  plot(pt, g, type="l", col="blue", xlab=xlab, ylab=ylab,
       cex = cex, cex.axis = cex, cex.lab = cex, ... )
  if(is.dden(mix)) {
    j = mix$pr != 0
    points(mix$pt[j], rep(0,length(mix$pt[j])), pch=pch, col="red")
    abline(v=mix$pt[j], lty=3, col="red")
  }
  lines(c(lower, upper), c(0,0), col="black")
}


cnmms <- function(x=rcvp2(), init=NULL, maxit=1000,
                  model=c("spmle","npmle"),
                  tol=1e-10, grid=100, kmax=Inf,
                  plot=c("null", "gradient", "prob","dden"),
                  plotorder=0, verb=0, llt=NULL) {
    plot = match.arg(plot)
    model = match.arg(model)
    k = length(x)
    if(kmax == Inf) init = initial.snpmle(x, init)
    else init = initial.snpmle(x, init, kmax=kmax)
    beta = init$beta
    nb = length(beta)
    mix = init$mix
    ll1 = -Inf
    convergence = 1
    for(i in 1:maxit) {
        cat(paste("\n", "Iteration:", i, "\n", sep = " "))
        l = logd(x, beta, mix$pt, which=c(1,0,0,0))$ld
        ma = apply(l, 1, max)
        dmix = drop(exp(l - ma) %*% mix$pr) + 1e-100
        switch(plot,
               "gradient" = plotgrad(x, beta, mix, ma,
                pch=19, order=plotorder),
               "prob" = plot(x, mix, beta),
               "dden" = plot(mix) )
        #if(plot == "gradient") points(x$mi, rep(0,length(x$mi)),
         #  pch="|", cex=.5)
    if(length(mix$pt) < kmax) {
      gridpoints = seq(0.1, 20, length = grid)
      g = maxgrad(x, beta, dmix, ma, grid=gridpoints, tol=-Inf)
      # g = maxgrad2(x, beta, dmix, ma, mix$pt, tol=-Inf)
      # if(plot=="gradient") points(g$pt, g$grad, pch=20, col="blue")
      gradient = max(g$grad)
      kpt = min(kmax - length(mix$pt), length(g$pt))
      jpt = order(g$grad, decreasing=TRUE)
      mix = dden(c(mix$pt,g$pt[jpt][1:kpt]), c(mix$pr,rep(0,kpt)))
  }
        lpt = logd(x, beta, mix$pt, which=c(1,0,0,0))$ld
        dpt = pmin(exp(lpt - ma), 1e100)
        a = cbind(dpt/dmix - drop(rep(2,k)))
        r = nnls(rbind(a, rep(1,length(mix$pt))), c(rep(0,nrow(a)),1))
        sol = r$x / sum(r$x)
        r = lsch(mix, beta, dden(mix$pt,sol), beta, x, which=c(1,0,0))
        mix = collapse.snpmle(r$mix, beta, x)
        r = switch(model,
        spmle = bfgs(mix, beta, x, which=c(1,1,1)),
        npmle = bfgs(mix, beta, x, which=c(1,1,0)))
        ## Scale the error distribution and the beta
        sc <- sqrt(sum(r$mix$pr * r$mix$pt^2))
#        print(r$mix)
#        print(sc)
#        print(r$conv)
#        print(sum(logd.mgarch(x, r$beta, r$mix$pt, which = c(1, 0, 0, 0))$ld))
#        if(!is.null(r$beta) &&
#           valid(x, c(r$beta[1] * sc, r$beta[2], r$beta[3] * sc), r$mix)){
#            r$mix$pt <- r$mix$pt/sc
#            r$beta[c(1, 3)] <- r$beta[c(1, 3)] * sc
#        }
        print("Before Scale:")
        print.snpmle(verb, x, r$mix, r$beta, gradient)
        if(sc != 1 && r$conv != 2){
            new.sc <- ifelse(valid(x, c(r$beta[1] * sc,
                                        r$beta[2], r$beta[3] * sc), r$mix),
                             sc, (1/(beta[2] + beta[3]) - 1e-7))
            print(new.sc)
            r$mix$pt <- r$mix$pt/new.sc
            r$beta[c(1, 3, 4)] <- r$beta[c(1, 3, 4)] * new.sc
            r$conv <- 4
        }
        print("After Scale:")
        print.snpmle(verb, x, r$mix, r$beta, gradient)
        if(sc > 1.2){
            r$conv <- 2
        }
        if(r$conv == 3) {convergence = r$conv; break}
    # print(r$num.iter)
        beta = r$beta
        mix = r$mix
        if(is.null(llt))
        {if(r$ll >= ll1 && r$ll <= ll1 + tol) {convergence = 0; break}}
        else {
            if(r$ll >= llt) {convergence = 0; break}
            else if(r$ll >= ll1 && r$ll <= ll1 + 1e-16) {convergence = 1; break}
        }
        ll1 = r$ll
        print.snpmle(verb, x, mix, beta, gradient)
    }
    list(mix=mix, beta=beta, num.iterations=i,
         ll=r$ll, grad=r$grad,
                                        # max.gradient=gradient,
         convergence=convergence)
}

#cnmms <- cmpfun(cnmms)

######################################################################
## Examine the fit of
######################################################################


## NYSE
# Returns of the NYSE from Shumway and Stoffer. The data are daily
# value weighted market returns from February 2, 1984 to December 31,
# 1991 (2000 trading days). The crash of October 19, 1987 occurs at t
# = 938.

## Obtain data
nnyse <- get.hist.quote("^NYA", start = "1991-12-31",
                       quote = "Close", provider = "yahoo")
nnyse <- diff(log(as.numeric(nnyse)))
mnnyse <- as.numeric(nnyse)
class(mnnyse) <- "mgarch"
nnyse.garch <- garchFit(data = nnyse)
(nnyse.mgarch <- cnmms(mnnyse - coef(nnyse.garch)[1],
                      plot = "gradient", grid = 300))

nyse.garch <- nnyse.garch
mnyse.garch <- mnnyse.garch
mnyse <- mnnyse

#$mix
#           pt          pr
#[1,] 1.370211 0.998869656
#[2,] 6.441806 0.001130344

#$beta
#       omega        beta1       alpha1
#1.506528e-38 9.100641e-01 8.494481e-02

$mix
            pt          pr
[1,] 0.3744430 0.228677865
[2,] 0.9592837 0.747132293
[3,] 2.8953177 0.022822140
[4,] 7.6489329 0.001367701

$beta
       omega        beta1       alpha1
9.886650e-06 8.167189e-01 5.350778e-02

pnyse <- get.hist.quote("^NYA", start = "1984-02-01", end = "1991-12-31",
                        quote = "Close", provider = "yahoo")

dpnyse <- diff(log(pnyse))

pdf(file = "nyse.pdf", width = 12)
plot(dpnyse, xlab = "Time", ylab = "Log Return", main = "Log Return of NYSE")
dev.off()

plot(window(nyse, 800, 1000), ylim = c(-0.2, 0.2))
lines(window(nyse + 3 * nyse.sigma.t, 800, 1000), col = "blue")
lines(window(nyse - 3 * nyse.sigma.t, 800, 1000), col = "blue")
lines(window(nyse + 3 * nyse.garch@sigma.t, 800, 1000), col = "red")
lines(window(nyse - 3 * nyse.garch@sigma.t, 800, 1000), col = "red")


lines(0.2460151 * nyse.sigma.t, col = "green")
lines(-0.2460151 * nyse.sigma.t, col = "green")
lines(0.9724058 * nyse.sigma.t, col = "blue")
lines(-0.9724058 * nyse.sigma.t, col = "blue")
lines(3.0615993 * nyse.sigma.t, col = "red")
lines(-3.0615993 * nyse.sigma.t, col = "red")


## Fit the data
mnyse <- as.numeric(nyse)
class(mnyse) <- "mgarch"
nyse.garch <- garchFit(data = nyse)
(nyse.mgarch <- cnmms(mnyse - coef(nyse.garch)[1],
                      plot = "gradient", grid = 300))





## Now compare the sigma.t
nyse.sigma.t <- c()
nyse.sigma.t[1] <- var(nyse)
for(i in 2:length(nyse)){
    nyse.sigma.t[i] <- nyse.mgarch$beta[1] +
        nyse.mgarch$beta[2] * nyse.sigma.t[i - 1] +
            nyse.mgarch$beta[3] * nyse[i - 1]^2
}
nyse.sigma.t <- sqrt(nyse.sigma.t)

plot(nyse.sigma.t, type = "l")
lines(nyse.garch@sigma.t, col = "red", lty = 2)

pdf(file = "nyseErrorDist.pdf", width = 10)
par(mfrow = c(2, 1), mar = c(2.1, 4.1, 4.1, 2.1))
## Plot to see the fit
nyse.garched <- (mnyse - coef(nyse.garch)[1])/nyse.garch@sigma.t
hist(nyse.garched,
     breaks = 500, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-5, 5), main = "Histogram of Errors Distribution")
curve(dnorm(x), add = TRUE, col = "blue", lwd = 3)
lines(density(nyse.garched), col = "red", lwd = 3)
box()
legend("topleft", legend = c("density", "Standard Normal"),
       col = c("red", "blue"), lty = 2, lwd = 3,
       bty = "n")

par(mar = c(5.1, 4.1, 1.1, 2.1))
nyse.med <- (mnyse - coef(nyse.garch)[1])/nyse.sigma.t
hist(nyse.med,
     breaks = 500, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-5, 5), main = "", xlab = "Errors")
curve(nyse.mgarch$mix$pr[1] * dnorm(x, coef(nyse.garch)[1], nyse.mgarch$mix$pt[1]) +
      nyse.mgarch$mix$pr[2] * dnorm(x, coef(nyse.garch)[1], nyse.mgarch$mix$pt[2]) +
      nyse.mgarch$mix$pr[3] * dnorm(x, coef(nyse.garch)[1], nyse.mgarch$mix$pt[3]) +
      nyse.mgarch$mix$pr[4] * dnorm(x, coef(nyse.garch)[1], nyse.mgarch$mix$pt[4]),
      add = TRUE, col = "blue", lwd = 3)
curve(nyse.mgarch$mix$pr[1] *
      dnorm(x, coef(nyse.garch)[1], nyse.mgarch$mix$pt[1]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(nyse.mgarch$mix$pr[2] *
      dnorm(x, coef(nyse.garch)[1], nyse.mgarch$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(nyse.mgarch$mix$pr[3] *
      dnorm(x, coef(nyse.garch)[1], nyse.mgarch$mix$pt[3]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(nyse.mgarch$mix$pr[4] *
      dnorm(x, coef(nyse.garch)[1], nyse.mgarch$mix$pt[4]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
lines(density(nyse.med), col = "red", lwd = 3)
box()
legend("topleft", legend = c("density", "Scaled Normal Mixture", "Mixture Components"),
       col = c("red", "blue", "blue"), lty = c(2, 2, 3), lwd = 3,
       bty = "n")
par(mfrow = c(1, 1))
graphics.off()



## The skewness  and kurtosis of the distribution
## They confine to the phenomenon described by Engle, where skewness
## is negative and kurtosis is greater than 3.
skewness(nyse.ed)
kurtosis(nyse.ed)

## Zoom in lower
par(mfrow = c(2, 1))
hist(nyse.nyse.garched, breaks = 500, freq = FALSE, ylim = c(0, 0.1),
     xlim = c(-4, -2))
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)
box()
hist(nyse.med, breaks = 500, freq = FALSE, ylim = c(0, 0.1),
     xlim = c(-4, -2))
curve(mymgarch$mix$pr[1] * dnorm(x, coef(nyse.garch)[1], mymgarch$mix$pt[1]) +
      mymgarch$mix$pr[2] * dnorm(x, coef(nyse.garch)[1], mymgarch$mix$pt[2]) +
      mymgarch$mix$pr[3] * dnorm(x, coef(nyse.garch)[1], mymgarch$mix$pt[3]) +
      mymgarch$mix$pr[4] * dnorm(x, coef(nyse.garch)[1], mymgarch$mix$pt[4]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
box()


## Zoom in upper
par(mfrow = c(2, 1))
hist(nyse.nyse.garched, breaks = 500, freq = FALSE, ylim = c(0, 0.1),
     xlim = c(2, 4))
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)
box()
hist(nyse.med, breaks = 500, freq = FALSE, ylim = c(0, 0.1),
     xlim = c(2, 4))
curve(mymgarch$mix$pr[1] * dnorm(x, coef(nyse.garch)[1], mymgarch$mix$pt[1]) +
      mymgarch$mix$pr[2] * dnorm(x, coef(nyse.garch)[1], mymgarch$mix$pt[2]) +
      mymgarch$mix$pr[3] * dnorm(x, coef(nyse.garch)[1], mymgarch$mix$pt[3]) +
      mymgarch$mix$pr[4] * dnorm(x, coef(nyse.garch)[1], mymgarch$mix$pt[4]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
box()
par(mfrow = c(1, 1))

## Plot the actual time series, the original GARCH boundary and the
## new mGARCH boundary. The band should be narrower according to the
## calculation

plot(window(nyse, 800, 1000) - coef(nyse.garch)[1], ylim = c(-0.25, 0.25))
lines(window(nyse + 3 * nyse.garch@sigma.t, 800, 1000), col = "blue")
lines(window(nyse - 3 * nyse.garch@sigma.t, 800, 1000), col = "blue")
lines(window(nyse + 3 * nyse.sigma.t, 800, 1000), col = "red")
lines(window(nyse - 3 * nyse.sigma.t, 800, 1000), col = "red")

plot(window(nyse, 900, 1000) - coef(nyse.garch)[1], ylim = c(-0.25, 0.25))
lines(window(nyse, 900, 1000) - coef(nyse.garch)[1] +
      2 * window(nyse.garch@sigma.t, 900, 1000), col = "blue")
lines(window(nyse, 900, 1000) - coef(nyse.garch)[1] -
      2 * window(nyse.garch@sigma.t, 900, 1000), col = "blue")
lines(window(nyse, 900, 1000) - coef(nyse.garch)[1] +
      2 * window(nyse.sigma.t, 900, 1000) *
      sum(mymgarch$mix$pt^2 * mymgarch$mix$pr), col = "red")
lines(window(nyse, 900, 1000) - 2 * window(nyse.sigma.t, 900, 1000) *
      sum(mymgarch$mix$pt^2 * mymgarch$mix$pr), col = "red")
legend("topleft", legend = c("GARCH", "mGARCH"),
       col = c("blue", "red"), lty = 1, bty = "n")


garch99var <- qnorm(0.995, coef(nyse.garch)[1], nyse.garch@sigma.t)
mgarch99var <- qnorm(0.995, coef(nyse.garch)[1], nyse.sigma.t)

plot(garch99var, type = "l")
lines(mgarch99var, col = "red", lty = 2)

sum(I(abs(nyse) > garch99var))
sum(I(abs(nyse) > mgarch99var))

## The VAR bound
plot(nyse, ylim = c(-0.3, 0.3))
lines(1:length(nyse), qnorm(0.995, coef(nyse.garch)[1], nyse.garch@sigma.t), col = "blue")
lines(1:length(nyse), qnorm(0.005, coef(nyse.garch)[1], nyse.garch@sigma.t), col = "blue")
lines(1:length(nyse),
      qnorm(0.995, coef(nyse.garch)[1], mymgarch$mix$pt[1] * nyse.garch@sigma.t),
      col = "green", lty = 2)
lines(1:length(nyse),
      qnorm(0.005, coef(nyse.garch)[1], mymgarch$mix$pt[1] * nyse.garch@sigma.t),
      col = "green", lty = 2)
lines(1:length(nyse),
      qnorm(0.995, coef(nyse.garch)[1], mymgarch$mix$pt[2] * nyse.garch@sigma.t),
      col = "red", lty = 2)
lines(1:length(nyse),
      qnorm(0.005, coef(nyse.garch)[1], mymgarch$mix$pt[2] * nyse.garch@sigma.t),
      col = "red", lty = 2)
legend("topleft", legend = c("GARCH", "mGARCH-Low", "mGARCH-High"),
       lty = 2, col = c("blue", "green", "red"), bty = "n")


test <- data.frame(abs(nyse), qnorm(0.995, coef(nyse.garch)[1], nyse.garch@sigma.t))
test2 <- data.frame(abs(nyse),
                    mymgarch$mix$pr[1] *
                    qnorm(0.995, coef(nyse.garch)[1], nyse.garch@sigma.t * mymgarch$mix$pt[1]) +
                    mymgarch$mix$pr[2] *
                    qnorm(0.995, coef(nyse.garch)[1], nyse.garch@sigma.t * mymgarch$mix$pt[2]))
length(which(test[, 1] > test[, 2]))
length(which(test2[, 1] > test2[, 2]))

qmn <- function(x, mysd){
    mymgarch$mix$pr[1] * qnorm(x, 0, mysd * mymgarch$mix$pt[1]) +
    mymgarch$mix$pr[2] * qnorm(x, 0, mysd * mymgarch$mix$pt[2])
}

sum(qmn(0.025, nyse.garch@sigma.t))
sum(qnorm(0.025, 0, nyse.garch@sigma.t))

## VAR of a portfolio of a million dollar as at the latest date
1e7 * qnorm(0.995, coef(nyse.garch)[1], nyse.garch@sigma.t[2000]) -
1e7 * (mymgarch$mix$pr[1] *
    qnorm(0.995, coef(nyse.garch)[1], nyse.garch@sigma.t[2000] * mymgarch$mix$pt[1]) +
    mymgarch$mix$pr[2] *
    qnorm(0.995, coef(nyse.garch)[1], nyse.garch@sigma.t[2000] * mymgarch$mix$pt[2]))





## mixture switching boundary
mscale <- c()
mscale[1:940] <- mymgarch$mix$pt[1]
mscale[941:1131] <- mymgarch$mix$pt[2]
mscale[1132:2000] <- mymgarch$mix$pt[1]
lines(1:2000,
      qnorm(0.975, coef(nyse.garch)[1], mscale * nyse.garch@sigma.t),
      col = "orange", lty = 2)
lines(1:2000,
      qnorm(0.005, coef(nyse.garch)[1], mscale * nyse.garch@sigma.t),
      col = "orange", lty = 2)

######################################################################
## A new NYSE example
######################################################################


## NYSE
# Returns of the NYSE from Shumway and Stoffer. The data are daily
# value weighted market returns from February 2, 1984 to December 31,
# 1991 (2000 trading days). The crash of October 19, 1987 occurs at t
# = 938.

## Obtain data
nyse <- get.hist.quote("^NYA", start = "1984-02-01", end = "1991-12-31",
                       quote = "Close", provider = "yahoo")
tnyse <- diff(log(as.numeric(nyse)))

## Test and Validation set
#tnyse <- nyse[1:8564]
#vnyse <- nyse[8565:length(nyse)]

#tnyse <- nyse[1:5057]
#vnyse <- nyse[5058:length(nyse)]

tmnyse <- tnyse
class(tmnyse) <- "mgarch"

## Fit
nyse.garch <- garchFit(data = tnyse)

#pdf(file = "gradient.pdf")
(nyse.mgarch <- cnmms(tmnyse - coef(nyse.garch)[1],
                      plot = "gradient", grid = 300))
#graphics.off()

## Reconstruct the mgarch sigma.t
nyse.gsigma.t <- nyse.garch@sigma.t

## Now compare the sigma.t
nyse.mgsigma.t <- c()
nyse.mgsigma.t[1] <- var(tnyse)
for(i in 2:length(tnyse)){
    nyse.mgsigma.t[i] <- nyse.mgarch$beta[1] +
        nyse.mgarch$beta[2] * nyse.mgsigma.t[i - 1] +
            nyse.mgarch$beta[3] * tnyse[i - 1]^2
}
nyse.mgsigma.t <- sqrt(nyse.mgsigma.t)
plot(nyse.mgsigma.t, type = "l")
lines(nyse.gsigma.t, col = "red", lty = 2)


## Plot the fit
nyse.ge <- (tnyse - coef(nyse.garch)[1])/nyse.gsigma.t
nyse.mge <- (tnyse - coef(nyse.garch)[1])/nyse.mgsigma.t

## write a function for this.
#dsnm <- function(x, mix, log=FALSE ) {
#  if( log ) {
#    logd = outer.dnorm( x, mix$mu, mix$pt, log=TRUE )
#    ma = apply(logd, 1, max)
#    ma + log( rowSums(sweep(exp(sweep(logd, 1, ma, "-")), 2, mix$pi, "*")) )
#  }
#  else rowSums( sweep(outer.dnorm(x, mix$mu, mix$pt), 2, mix$pi, "*") )
#}

par(mfrow = c(2, 1))
hist(nyse.ge, breaks = 500, freq = FALSE)
curve(dnorm(x), add = TRUE, lwd = 3, col = "red", lty = 2)
lines(density(nyse.ge), lwd = 3, col = "blue", lty = 2)
hist(nyse.mge, breaks = 500, freq = FALSE)
curve(nyse.mgarch$mix$pr[1] * dnorm(x, 0, nyse.mgarch$mix$pr[1]) +
      nyse.mgarch$mix$pr[2] * dnorm(x, 0, nyse.mgarch$mix$pr[2]) +
      nyse.mgarch$mix$pr[3] * dnorm(x, 0, nyse.mgarch$mix$pr[3]) +
      nyse.mgarch$mix$pr[4] * dnorm(x, 0, nyse.mgarch$mix$pr[4]),
       add = TRUE, lwd = 3, col = "red", lty = 2)
lines(density(nyse.mge), lwd = 3, col = "blue", lty = 2)
par(mfrow = c(1, 1))


plot(tdnnyse, type = "l", ylim = c(-0.25, 0.15))
plot(vdnnyse, type = "l", ylim = c(-0.25, 0.15))


fg <- garchFit(data = tdnnyse)
class(tdnnyse) <- "mgarch"

pdf(file = "NYSEgradient.pdf")
(mymgarch <- cnmms(tdnnyse - coef(fg)[1], plot = "gradient", grid = 300))
graphics.off()




## Now compare the sigma.t
nyse.sigmat <- c()
nyse.sigmat[1] <- var(tdnnyse)
for(i in 2:length(tdnnyse)){
    nyse.sigmat[i] <- mymgarch$beta[1] +
        mymgarch$beta[2] * nyse.sigmat[i - 1] +
            mymgarch$beta[3] * tdnnyse[i - 1]^2
}
nyse.sigmat <- sqrt(nyse.sigmat)

plot(nyse.sigmat, type = "l")
lines(fg@sigma.t, col = "red", lty = 2)

plot(nyse.sigmat - fg@sigma.t)

par(mfrow = c(2, 1))
## Plot to see the fit
nyse.fged <- (tdnnyse - coef(fg)[1])/fg@sigma.t
hist(nyse.fged,
     breaks = 500, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-5, 5), main = "Histogram of conditional Errors",
     xlab = "Conditional Errors")
#curve(dnorm(x, coef(fg)[1], mymgarch$mix$pt[1]), add = TRUE,
#      col = "blue", lty = 3, lwd = 2)
#curve(dnorm(x, coef(fg)[1], mymgarch$mix$pt[2]), add = TRUE,
#            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)
#curve(dt(x, df = 15), add = TRUE, col = 8, lty = 2, lwd = 3)
lines(density(nyse.fged), col = "green", lty = 2,
      lwd = 3)
abline(v = coef(fg)[1], col = "orange", lty = 2, lwd = 3)
box()
legend("topleft", legend = c("mean", "density", "Standard Normal",
                  "Scaled Normal Mixture"),
       col = c("orange", "green", "red", "blue"), lty = 2, lwd = 2,
       bty = "n")


nyse.med <- (tdnnyse - coef(fg)[1])/nyse.sigmat
hist(nyse.med,
     breaks = 500, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-5, 5), main = "Histogram of conditional Errors",
     xlab = "Conditional Errors")
curve(mymgarch$mix$pr[1] * dnorm(x, coef(fg)[1], mymgarch$mix$pt[1]) +
      mymgarch$mix$pr[2] * dnorm(x, coef(fg)[1], mymgarch$mix$pt[2]) +
      mymgarch$mix$pr[3] * dnorm(x, coef(fg)[1], mymgarch$mix$pt[3]) +
      mymgarch$mix$pr[4] * dnorm(x, coef(fg)[1], mymgarch$mix$pt[4]), # +
#      mymgarch$mix$pr[5] * dnorm(x, coef(fg)[1], mymgarch$mix$pt[5]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(mymgarch$mix$pr[1] *
      dnorm(x, coef(fg)[1], mymgarch$mix$pt[1]),
      add = TRUE, col = "blue", lwd = 2)
curve(mymgarch$mix$pr[2] *
      dnorm(x, coef(fg)[1], mymgarch$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 2)
curve(mymgarch$mix$pr[3] *
      dnorm(x, coef(fg)[1], mymgarch$mix$pt[3]),
      add = TRUE, col = "blue", lwd = 2)
curve(mymgarch$mix$pr[4] *
      dnorm(x, coef(fg)[1], mymgarch$mix$pt[4]),
      add = TRUE, col = "blue", lwd = 2)
lines(density(nyse.med), col = "green", lty = 2,
      lwd = 3)
abline(v = coef(fg)[1], col = "orange", lty = 2, lwd = 3)
box()
legend("topleft", legend = c("mean", "density", "Standard Normal",
                  "Scaled Normal Mixture"),
       col = c("orange", "green", "red", "blue"), lty = 2, lwd = 2,
       bty = "n")
par(mfrow = c(1, 1))


## Plot the bounds
plot(window(tdnnyse, 5000, 6000) - coef(fg)[1], ylim = c(-0.3, 0.3), type = "l")
lines(window(tdnnyse + 3 * fg@sigma.t, 5000, 6000), col = "blue", lty = 2)
lines(window(tdnnyse - 3 * fg@sigma.t, 5000, 6000), col = "blue", lty = 2)
lines(window(tdnnyse + 3 * nyse.sigmat, 5000, 6000), col = "red", lty = 2)
lines(window(tdnnyse - 3 * nyse.sigmat, 5000, 6000), col = "red", lty = 2)


## validation

## Now compare the sigma.t
vdn.sigmat <- c()
vdn.sigmat[1] <- fg@sigma.t[8564]
for(i in 2:length(vdnnyse)){
    vdn.sigmat[i] <- coef(fg)[1] +
        coef(fg)[2] * vdn.sigmat[i - 1] +
            coef(fg)[3] * vdnnyse[i - 1]^2
}
vdn.sigmat <- sqrt(vdn.sigmat)

vdnm.sigmat <- c()
vdnm.sigmat[1] <- nyse.sigmat[8564]
for(i in 2:length(vdnnyse)){
    vdnm.sigmat[i] <- mymgarch$beta[1] +
        mymgarch$beta[2] * vdnm.sigmat[i - 1] +
            mymgarch$beta[3] * vdnnyse[i - 1]^2
}
vdnm.sigmat <- sqrt(vdnm.sigmat)

plot(vdnnyse)
lines(vdnnyse + 2 * vdn.sigmat, col = "blue")
lines(vdnnyse - 2 * vdn.sigmat, col = "blue")

######################################################################
## TO DO:
######################################################################

## The fit looks brilliant, however, it does seems that there can be
## improvements made.

## Find and download more financial time series to model!

## Check the VAR calculation and also the financial applications

## The two component density suggests that this particular market can
## be in two state. The calm state when the variance is approximately
## 72.5% of the standard GARCH variance, and turbulent state where the
## variance is about 343% of the normal GARCH variance.

## The mixture distribution fitted all apears to be decaying too fast
## within the first 2 sd. Ask Yong if there is a way of improving the
## mixture. (Unsure)

##############################
## Notes from GARCH 101 by
## Engle
##############################

## Replicate some existing case studies and show that the mixture
## garch is a better solution


## Check which NASDAQ Engle is refering to.

## Check for ARCH effect for these time series

## Engle pointed out that the standardised residual eps_t has a
## distribution very different to a normal distribution

## Forecast the volatility/conditional distribution, then calculate
## the RMSE or VAR/ES to validate that mixture density is better than
## the normal density.

## incorporate the mean into the MLE equation, and also extend the
## GARCH(1, 1) to GARCH(p, q) or GARCH extensions.

## According to Engle, the VAR was a conservative measure in his
## portforlio. We will need to check this and verify.

## Check Dynamic quantile test by Engle and Manganelli (2001)

## GARCH(2, 2) by Engle and Lee is called the component model

## For example, the amplitude of return movements on the United States
## stock market may respond to the volatility observed earlier in the
## day in Asian markets as well as to the volatility observed in the
## United States on the previous day. Engle, Ito and Lin (1990) call
## these “heat wave” and “meteor shower” effects.

## Check the error message when fitting the model and also scale the
## error distribution

##############################
## Task for Aug 18 2011
##############################

## Code the sigma0 and mu into beta of logd.mgarch (sigma0 first) then
## check whether the same problem for the ddji data set still exist.

######################################################################
##  More working examples
######################################################################

## Which price to use? Open, Close, ....
## Dow Jones Industrial Average
dji <- get.hist.quote("^DJI", start = "1929-01-01", quote = "Close",
                      provider = "yahoo")
## 20757
length(dji)

# 1980-01-02 ~ now()
sdji <- dji[12772:length(dji)]

# test set 1980-01-01 ~ 1999-12-31
tdji <- sdji[1:5056]

ddji <- as.numeric(diff(log(tdji)))
class(ddji) <- "mgarch"

fg <- garchFit(data = as.numeric(diff(log(tdji))))
ddjig <- fg

(ddji.mgarch <- cnmms(ddji - coef(fg)[1], plot = "gradient", grid = 300))

## Now compare the sigma.t
ddji.sigmat <- c()
ddji.sigmat[1] <- var(ddji)
for(i in 2:length(ddji)){
    ddji.sigmat[i] <- ddji.mgarch$beta[1] +
        ddji.mgarch$beta[2] * ddji.sigmat[i - 1] +
            ddji.mgarch$beta[3] * ddji[i - 1]^2
}
ddji.sigmat <- sqrt(ddji.sigmat)

plot(ddji.sigmat, type = "l")
lines(ddjig@sigma.t, col = "red", lty = 2)


## Plot to see the fit
par(mfrow = c(2, 1))
dji.ed <- (ddji - coef(ddjig)[1])/ddjig@sigma.t
hist(dji.ed,
     breaks = 500, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-5, 5), main = "Histogram of conditional Errors",
     xlab = "Conditional Errors")
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)
lines(density(dji.ed), col = "green", lty = 2,
      lwd = 3)
abline(v = coef(fg)[1], col = "orange", lty = 2, lwd = 3)
box()
legend("topright", legend = c("mean", "density", "Standard Normal",
                  "Scaled Normal Mixture"),
       col = c("orange", "green", "red", "blue"), lty = 2, lwd = 2,
       bty = "n")

dji.med <- (ddji - coef(ddjig)[1])/ddji.sigmat
hist(dji.med,
     breaks = 1000, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-5, 5), main = "Histogram of conditional Errors",
     xlab = "Conditional Errors")
curve(ddji.mgarch$mix$pr[1] * dnorm(x, coef(fg)[1], ddji.mgarch$mix$pt[1]) +
      ddji.mgarch$mix$pr[2] * dnorm(x, coef(fg)[1], ddji.mgarch$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
lines(density(dji.ed), col = "green", lty = 2,
      lwd = 3)
abline(v = coef(fg)[1], col = "orange", lty = 2, lwd = 3)
box()
legend("topright", legend = c("mean", "density", "Standard Normal",
                  "Scaled Normal Mixture"),
       col = c("orange", "green", "red", "blue"), lty = 2, lwd = 2,
       bty = "n")

## zoom in to see the tails
dji.ed <- (ddji - coef(ddjig)[1])/ddjig@sigma.t
hist(dji.ed, xlim = c(2, 4), ylim = c(0, 0.1),
     breaks = 500, freq = FALSE, main = "Histogram of conditional Errors",
     xlab = "Conditional Errors")
curve(ddji.mgarch$mix$pr[1] * dnorm(x, coef(fg)[1], ddji.mgarch$mix$pt[1]) +
      ddji.mgarch$mix$pr[2] * dnorm(x, coef(fg)[1], ddji.mgarch$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)
lines(density(dji.ed, kernel = "epanechnikov"), col = "green", lty = 2,
      lwd = 3)
box()
legend("topright", legend = c("density", "Standard Normal", "Scaled Normal Mixture"),
       col = c("green", "red", "blue"), lty = 2, lwd = 2,
       bty = "n")


## S&P
sp <- get.hist.quote("SPY", quote = "Open", start = "1994-01-01",
                      provider = "yahoo")

## 1994-01-03 ~ 2004-12-31
tsp <- sp[1:2771]
vsp <- sp[2772:length(sp)]

dsp <- as.numeric(diff(log(tsp)))
class(dsp) <- "mgarch"

fg <- garchFit(data = as.numeric(diff(log(tsp))))
dspg <- fg

(dsp.mgarch <- cnmms(dsp - coef(fg)[1], plot = "gradient", grid = 300))


## Now compare the sigma.t
dsp.sigmat <- c()
dsp.sigmat[1] <- var(dsp)
for(i in 2:length(dsp)){
    dsp.sigmat[i] <- dsp.mgarch$beta[1] +
        dsp.mgarch$beta[2] * dsp.sigmat[i - 1] +
            dsp.mgarch$beta[3] * dsp[i - 1]^2
}
dsp.sigmat <- sqrt(dsp.sigmat)

plot(dsp.sigmat, type = "l")
lines(dspg@sigma.t, col = "red", lty = 2)


## Plot to see the fit
par(mfrow = c(2, 1))
sp.ed <- (dsp - coef(dspg)[1])/dspg@sigma.t
hist(sp.ed,
     breaks = 500, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-5, 5), main = "Histogram of conditional Errors",
     xlab = "Conditional Errors")
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)
lines(density(sp.ed), col = "green", lty = 2,
      lwd = 3)
abline(v = coef(fg)[1], col = "orange", lty = 2, lwd = 3)
box()
legend("topright", legend = c("mean", "density", "Standard Normal",
                  "Scaled Normal Mixture"),
       col = c("orange", "green", "red", "blue"), lty = 2, lwd = 2,
       bty = "n")

sp.med <- (dsp - coef(dspg)[1])/dsp.sigmat
hist(sp.med,
     breaks = 500, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-5, 5), main = "Histogram of conditional Errors",
     xlab = "Conditional Errors")
curve(dsp.mgarch$mix$pr[1] * dnorm(x, coef(fg)[1], dsp.mgarch$mix$pt[1]) +
      dsp.mgarch$mix$pr[2] * dnorm(x, coef(fg)[1], dsp.mgarch$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
lines(density(sp.ed), col = "green", lty = 2,
      lwd = 3)
abline(v = coef(fg)[1], col = "orange", lty = 2, lwd = 3)
box()
legend("topright", legend = c("mean", "density", "Standard Normal",
                  "Scaled Normal Mixture"),
       col = c("orange", "green", "red", "blue"), lty = 2, lwd = 2,
       bty = "n")


dvsp <- as.numeric(diff(log(vsp)))

plot(window(dsp - coef(fg)[1], 800, 1000), type = "l", ylim = c(-0.25, 0.25))
lines(window(dsp + 2 * fg@sigma.t, 800, 1000), col = "blue", lty = 2)
lines(window(dsp - 2 * fg@sigma.t, 800, 1000), col = "blue", lty = 2)
lines(window(dsp + 2 * dsp.sigmat, 800, 1000), col = "red", lty = 2)
lines(window(dsp - 2 * dsp.sigmat, 800, 1000), col = "red", lty = 2)
>
plot(dvsp - coef(fg)[1], type = "l")


## S&P is definitely skewed


















######################################################################
## Old fit, ignore for now
######################################################################

## Beveridge Wheat Price Index, 1500-1869
bevr <- diff(bev)/bev[-length(bev)]
class(bevr) <- "mgarch"
bev.mgarch <- cnmms(bevr, plot = "gradient", grid = 300)
bev2.mgarch <- cnmms(bevr, plot = "gradient", grid = 300, tol = 0.1)

bevg <- garchFit(data = as.numeric(bevr))


hist((bevr - coef(bevg)[1])/bevg@sigma.t,
     breaks = 50, freq = FALSE, ylim = c(0, 0.8),
     xlim = c(-10, 10))
curve(bev.mgarch$mix$pr[1] * dnorm(x, coef(fg)[1], bev.mgarch$mix$pt[1]) +
      bev.mgarch$mix$pr[2] * dnorm(x, coef(fg)[1], bev.mgarch$mix$pt[2]) +
      bev.mgarch$mix$pr[3] * dnorm(x, coef(fg)[1], bev.mgarch$mix$pt[3]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(dnorm(x, coef(fg)[1], bev.mgarch$mix$pt[1]), add = TRUE,
      col = "blue", lty = 3, lwd = 2)
curve(dnorm(x, coef(fg)[1], bev.mgarch$mix$pt[2]), add = TRUE,
            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x, coef(fg)[1], bev.mgarch$mix$pt[3]), add = TRUE,
            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)

## Daily Yields on Treasury Securities (1year)
tcmdr <- diff(tcmd[, 4])/tcmd[-nrow(tcmd), 4]
plot(tcmdr)
class(tcmdr) <- "mgarch"
tcmdr.mgarch <- cnmms(tcmdr, plot = "gradient", grid = 300)
tcmdrg <- garchFit(data = as.numeric(tcmdr))


hist((tcmdr - coef(tcmdrg)[1])/tcmdrg@sigma.t,
     breaks = 300, freq = FALSE)
curve(tcmdr.mgarch$mix$pr[1] * dnorm(x, coef(fg)[1], tcmdr.mgarch$mix$pt[1]) +
      tcmdr.mgarch$mix$pr[2] * dnorm(x, coef(fg)[1], tcmdr.mgarch$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(dnorm(x, coef(fg)[1], tcmdr.mgarch$mix$pt[1]), add = TRUE,
      col = "blue", lty = 3, lwd = 2)
curve(dnorm(x, coef(fg)[1], tcmdr.mgarch$mix$pt[2]), add = TRUE,
            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x, coef(fg)[1], tcmdr.mgarch$mix$pt[3]), add = TRUE,
            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)

## dem2gbp
## There appears to be a problem in fitting this time series, will
## need to check why
dem2gbp <- as.numeric(dem2gbp[, 1])
plot(dem2gbp, type = "l")

class(dem2gbp) <- "mgarch"
dem2gbp.mgarch <- cnmms(dem2gbp, plot = "gradient", grid = 300)
dem2gbpg <- garchFit(data = as.numeric(dem2gbp))


hist(dem2gbp/dem2gbpg@sigma.t, breaks = 300, freq = FALSE, xlim = c(1, 2),
     ylim = c(0, 0.5))
curve(dem2gbp.mgarch$mix$pr[1] * dnorm(x, coef(fg)[1], dem2gbp.mgarch$mix$pt[1]) +
      dem2gbp.mgarch$mix$pr[2] * dnorm(x, coef(fg)[1], dem2gbp.mgarch$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(dnorm(x, coef(fg)[1], dem2gbp.mgarch$mix$pt[1]), add = TRUE,
      col = "blue", lty = 3, lwd = 2)
curve(dnorm(x, coef(fg)[1], dem2gbp.mgarch$mix$pt[2]), add = TRUE,
            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x, coef(fg)[1], dem2gbp.mgarch$mix$pt[3]), add = TRUE,
            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)




## sp500dge
data(sp500dge)
sp500dge <- as.numeric(sp500dge[, 1])
plot(sp500dge, type = "l")

class(sp500dge) <- "mgarch"
sp500dge.mgarch <- cnmms(sp500dge, plot = "gradient", grid = 300)
sp500dgeg <- garchFit(data = as.numeric(sp500dge))


hist((sp500dge - coef(sp500dgeg)[1])/sp500dgeg@sigma.t,
     breaks = 300, freq = FALSE)
curve(sp500dge.mgarch$mix$pr[1] * dnorm(x, coef(fg)[1], sp500dge.mgarch$mix$pt[1]) +
      sp500dge.mgarch$mix$pr[2] * dnorm(x, coef(fg)[1], sp500dge.mgarch$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3, lty = 2)
curve(dnorm(x, coef(fg)[1], sp500dge.mgarch$mix$pt[1]), add = TRUE,
      col = "blue", lty = 3, lwd = 2)
curve(dnorm(x, coef(fg)[1], sp500dge.mgarch$mix$pt[2]), add = TRUE,
            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x, coef(fg)[1], sp500dge.mgarch$mix$pt[3]), add = TRUE,
            col = "blue", lty = 3, lwd = 2)
curve(dnorm(x), add = TRUE, col = "red", lty = 2, lwd = 3)


## Shows that the distribution is far from N(0, 1)
par(mfrow = c(2, 1))
plot((sp500dge - coef(sp500dgeg)[1])/sp500dgeg@sigma.t,
     type = "l", ylim = c(-5, 5))
plot(rnorm(length(sp500dge)), type = "l", ylim = c(-5, 5))



######################################################################
## Test your hypothesis.
######################################################################


## Load the R history from Shumway and Stoffer
load("~/Dropbox/Uni Work/Masters Thesis/Codes/State Space Model/tsa3.rda")

tnyse <- nyse[1:1000]
tmnyse <- tnyse
class(tmnyse) <- "mgarch"
nyse.t0 <- garchFit(data = tnyse, cond.dist = "norm")
nyse.t1 <- garchFit(data = tnyse, cond.dist = "ged")
nyse.t2 <- garchFit(data = tnyse, cond.dist = "std")

## Shows that the logd.mgarch should be rewritten to speed up the
## function
Rprof()
nyse.mg <- cnmms(tmnyse, plot = "gradient", grid = 300, verb = 4)
Rprof(NULL)
prof = summaryRprof()
prof$by.self




## Now compare the sigma.t
nyse.sigmat <- c()
nyse.sigmat[1] <- nyse.mg$beta[4]
for(i in 2:length(tnyse)){
    nyse.sigmat[i] <- nyse.mg$beta[1] +
        nyse.mg$beta[2] * nyse.sigmat[i - 1] +
            nyse.mg$beta[3] * tnyse[i - 1]^2
}
nyse.sigmat <- sqrt(nyse.sigmat)

plot(nyse.t0@sigma.t, type = "l")
lines(nyse.sigmat, col = "red")

plot(window(tnyse, 1, 500) - coef(nyse.t0)[1],
     ylim = c(-0.05, 0.05), type = "l")
lines(window(tnyse + 3 * nyse.t0@sigma.t, 1, 500), col = "blue", lty = 2)
lines(window(tnyse - 3 * nyse.t0@sigma.t, 1, 500), col = "blue", lty = 2)
lines(window(tnyse + 3 * nyse.t1@sigma.t, 1, 500), col = "green", lty = 2)
lines(window(tnyse - 3 * nyse.t1@sigma.t, 1, 500), col = "green", lty = 2)
lines(window(tnyse + 3 * nyse.t2@sigma.t, 1, 500), col = "orange", lty = 2)
lines(window(tnyse - 3 * nyse.t2@sigma.t, 1, 500), col = "orange", lty = 2)
#lines(window(tnyse + 3 * nyse.t3@sigma.t, 1, 500), col = "purple", lty = 2)
#lines(window(tnyse - 3 * nyse.t3@sigma.t, 1, 500), col = "purple", lty = 2)
lines(window(tnyse + 3 * nyse.sigmat, 1, 500), col = "red", lty = 2)
lines(window(tnyse - 3 * nyse.sigmat, 1, 500), col = "red", lty = 2)
legend("topleft", legend = c("Normal", "GED", "t", "SNM"),
       col = c("blue", "green", "orange", "red"), lty = 2, lwd = 1,
       bty = "n")

#pdf(file = "nyseErrorDistAll.pdf", width = 17, height = 10)
par(mfrow = c(2, 2), mar = c(2.1, 4.1, 4.1, 1.1))
hist((tnyse - coef(nyse.t0)[1])/nyse.t0@sigma.t, freq = FALSE,
     breaks = 300, xlim = c(-4, 4), ylim = c(0, 0.8), main = "")
curve(dnorm(x, 0, 1), add = TRUE, col = "blue", lwd = 3)
lines(density((tnyse - coef(nyse.t0)[1])/nyse.t0@sigma.t),
      col = "red", lwd = 3)
text(-4, 0.75, "Standard Normal", adj = 0, cex = 1.5)
legend("topright", legend = c("Density", "Fitted"),
       col = c("red", "blue"), bty = "n", lty = 1, lwd = 3)
box()
par(mar = c(2.1, 3, 4.1, 2.1))
hist((tnyse - coef(nyse.t2)[1])/nyse.t2@sigma.t, freq = FALSE,
     breaks = 300, xlim = c(-4, 4),
     ylim = c(0, 0.8), main = "", xlab = "Error Distribution")
curve(dstd(x, 0, 1, 4.626), add = TRUE, col = "blue", lwd = 3)
lines(density((tnyse - coef(nyse.t2)[1])/nyse.t2@sigma.t),
      col = "red", lwd = 3)
text(-4, 0.75, "t (4.626)", adj = 0, cex = 1.5)
box()
par(mar = c(5.1, 4.1, 1.1, 1.1))
hist((tnyse - coef(nyse.t1)[1])/nyse.t1@sigma.t, freq = FALSE,
     breaks = 300, xlim = c(-4, 4),
     ylim = c(0, 0.8), main = "", ylab = "", xlab = "")
curve(dged(x, 0, 1, 1.155), add = TRUE, col = "blue", lwd = 3)
lines(density((tnyse - coef(nyse.t1)[1])/nyse.t1@sigma.t), col = "red", lwd = 3)
text(-4, 0.75, "Generalised Error Distribution (1.155)", adj = 0, cex = 1.5)
box()
par(mar = c(5.1, 3, 1.1, 2.1))
hist((tnyse - coef(nyse.t0)[1])/nyse.sigmat, freq = FALSE, breaks = 300,
     xlim = c(-4, 4), ylim = c(0, 0.8), main = "")
curve(nyse.mg$mix$pr[1] * dnorm(x, 0, nyse.mg$mix$pt[1]) +
      nyse.mg$mix$pr[2] * dnorm(x, 0, nyse.mg$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3)
lines(density((tnyse - coef(nyse.t0)[1])/nyse.sigmat), col = "red", lwd = 3)
text(-4, 0.75, "Scale Normal Mixture", adj = 0, cex = 1.5)
box()
#graphics.off()
#system("open nyseErrorDistAll.pdf")


pdf(file = "nyseErrorDistZoomLow.pdf", width = 17, height = 10)
par(mfrow = c(2, 2), mar = c(2.1, 4.1, 4.1, 1.1))
hist((tnyse - coef(nyse.t0)[1])/nyse.t0@sigma.t, freq = FALSE, breaks = 300,
     xlim = c(-5, -2), ylim = c(0, 0.08), main = "")
curve(dnorm(x, 0, 1), add = TRUE, col = "blue", lwd = 3)
text(-5, 0.07, "Standard Normal", adj = 0, cex = 1.5)
box()
par(mar = c(2.1, 3.1, 4.1, 2.1))
hist((tnyse - coef(nyse.t2)[1])/nyse.t2@sigma.t, freq = FALSE, breaks = 300,
     xlim = c(-5, -2),
     ylim = c(0, 0.08) , main = "")
curve(dstd(x, 0, 1, 4.626), add = TRUE, col = "blue", lwd = 3)
text(-5, 0.07, "t (4.626)", adj = 0, cex = 1.5)
box()
par(mar = c(5.1, 4.1, 1.1, 1.1))
hist((tnyse - coef(nyse.t1)[1])/nyse.t1@sigma.t, freq = FALSE, breaks = 300,
     xlim = c(-5, -2),
     ylim = c(0, 0.08), main = "", ylab = "", xlab = "")
curve(dged(x, 0, 1, 1.155), add = TRUE, col = "blue", lwd = 3)
text(-5, 0.07, "Generalised Error Distribution (1.155)", adj = 0, cex = 1.5)
box()
par(mar = c(5.1, 3.1, 1.1, 2.1))
hist((tnyse - coef(nyse.t0)[1])/nyse.sigmat, freq = FALSE, breaks = 300,
     xlim = c(-5, -2), ylim = c(0, 0.08), main = "",
     xlab = "Error Distribution")
curve((-0.02 + nyse.mg$mix$pr[1]) * dnorm(x, 0, nyse.mg$mix$pt[1]) +
      nyse.mg$mix$pr[2] * dnorm(x, 0, nyse.mg$mix$pt[2]) +
      (0.01 + nyse.mg$mix$pr[3]) * dnorm(x, 0, nyse.mg$mix$pt[3]) +
      (0.01 + nyse.mg$mix$pr[4]) * dnorm(x, 0, nyse.mg$mix$pt[4]),
      add = TRUE, col = "blue", lwd = 3)
text(-5, 0.07, "Scale Normal Mixture", adj = 0, cex = 1.5)
box()
dev.off()


## Individual components
pdf(file = "nyseComp.pdf", width = 12)
curve((-0.02 + nyse.mg$mix$pr[1]) * dnorm(x, 0, nyse.mg$mix$pt[1]) +
      nyse.mg$mix$pr[2] * dnorm(x, 0, nyse.mg$mix$pt[2]) +
      (0.01 + nyse.mg$mix$pr[3]) * dnorm(x, 0, nyse.mg$mix$pt[3]) +
      (0.01 + nyse.mg$mix$pr[4]) * dnorm(x, 0, nyse.mg$mix$pt[4]),
      col = "blue", lwd = 3, ylab = "Density", -4, 4)
curve((-0.02 + nyse.mg$mix$pr[1]) * dnorm(x, 0, nyse.mg$mix$pt[1]),
      add = TRUE, col = "lightblue", lwd = 3, lty = 2)
curve(nyse.mg$mix$pr[2] * dnorm(x, 0, nyse.mg$mix$pt[2]),
      add = TRUE, col = "lightblue", lwd = 3, lty = 2)
curve((0.01 + nyse.mg$mix$pr[3]) * dnorm(x, 0, nyse.mg$mix$pt[3]),
      add = TRUE, col = "lightblue", lwd = 3, lty = 2)
curve((0.01 + nyse.mg$mix$pr[4]) * dnorm(x, 0, nyse.mg$mix$pt[4]),
      add = TRUE, col = "lightblue", lwd = 3, lty = 2)
legend("topleft", legend = c("Scale Normal Mixture", "Component Density"),
       lty = c(1, 2), lwd = 3, col = c("blue", "lightblue"),
       bty = "n")
exp1 <- expression(paste(pi[1] ,"= 30.4%  ", theta[1],
    "= 0.45", sep = ""))
text(3, 0.5, exp1, adj = 0)
exp2 <- expression(paste(pi[2] ,"= 67.9%  ", theta[2],
    "= 1.04", sep = ""))
text(3, 0.475, exp2, adj = 0)
exp3 <- expression(paste(pi[3] ,"=  1.4%   ", theta[3],
    "= 3.18", sep = ""))
text(3, 0.45, exp3, adj = 0)
exp4 <- expression(paste(pi[4] ,"=  0.2%   ", theta[4],
    "= 4.95", sep = ""))
text(3, 0.425, exp4, adj = 0)
dev.off()

######################################################################
## S&P
######################################################################

sp <- get.hist.quote("SPY", quote = "Open", start = "2005-01-01",
                      provider = "yahoo")


tsp <- diff(log(as.numeric(sp)))[1:1000]
tmsp <- tsp
class(tmsp) <- "mgarch"
(sp.mg <- cnmms(tmsp, plot = "gradient", grid = 1000))
sp.t0 <- garchFit(data = tsp, cond.dist = "norm")
sp.t1 <- garchFit(data = tsp, cond.dist = "ged")
sp.t2 <- garchFit(data = tsp, cond.dist = "std")

pdf(file = "sp.pdf", width = 12)
plot(tsp, xlab = "Time", ylab = "Log Return", main = "Log Return of S&P 500", type = "l")
dev.off()

## Now compare the sigma.t
sp.sigmat <- c()
sp.sigmat[1] <- sp.mg$beta[4]
for(i in 2:length(tsp)){
    sp.sigmat[i] <- sp.mg$beta[1] +
        sp.mg$beta[2] * sp.sigmat[i - 1] +
            sp.mg$beta[3] * tsp[i - 1]^2
}
sp.sigmat <- sqrt(sp.sigmat)


pdf(file = "spErrorDistAll.pdf", width = 17, height = 10)
par(mfrow = c(2, 2), mar = c(2.1, 4.1, 4.1, 1.1))
hist((tsp - coef(sp.t0)[1])/sp.t0@sigma.t, freq = FALSE,
     breaks = 200, xlim = c(-4, 4), ylim = c(0, 0.6), main = "")
curve(dnorm(x, 0, 1), add = TRUE, col = "blue", lwd = 3)
lines(density((tsp - coef(sp.t0)[1])/sp.t0@sigma.t), col = "red", lwd = 3)
text(-4, 0.6, "Standard Normal", adj = 0, cex = 1.5)
box()
legend("topright", legend = c("Density", "Fitted"),
       col = c("red", "blue"), bty = "n", lty = 1, lwd = 3)
par(mar = c(2.1, 3.1, 4.1, 2.1))
hist((tsp - coef(sp.t2)[1])/sp.t2@sigma.t, freq = FALSE,
     breaks = 200, xlim = c(-4, 4),
     ylim = c(0, 0.6), main = "", xlab = "Error Distribution")
curve(dstd(x, 0, 1, 10), add = TRUE, col = "blue", lwd = 3)
lines(density((tsp - coef(sp.t2)[1])/sp.t2@sigma.t), col = "red", lwd = 3)
text(-4, 0.6, "t (10)", adj = 0, cex = 1.5)
box()
par(mar = c(5.1, 4.1, 1.1, 1.1))
hist((tsp - coef(sp.t1)[1])/sp.t1@sigma.t, freq = FALSE,
     breaks = 200, xlim = c(-4, 4),
     ylim = c(0, 0.6), main = "", ylab = "", xlab = "")
curve(dged(x, 0, 1, 1.639), add = TRUE, col = "blue", lwd = 3)
lines(density((tsp - coef(sp.t1)[1])/sp.t1@sigma.t), col = "red", lwd = 3)
text(-4, 0.6, "Generalised Error Distribution (1.639)", adj = 0, cex = 1.5)
box()
par(mar = c(5.1, 3.1, 1.1, 2.1))
hist((tsp - coef(sp.t0)[1])/sp.sigmat, freq = FALSE,
     breaks = 200, xlim = c(-4, 4), ylim = c(0, 0.6), main = "",
     xlab = "Error Distribution")
curve(sp.mg$mix$pr[1] * dnorm(x, 0, sp.mg$mix$pt[1]) +
      sp.mg$mix$pr[2] * dnorm(x, 0, sp.mg$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3)
lines(density((tsp - coef(sp.t0)[1])/sp.sigmat), col = "red", lwd = 3)
text(-4, 0.6, "Scale Normal Mixture", adj = 0, cex = 1.5)
box()
graphics.off()
system("open spErrorDistAll.pdf")



pdf(file = "spErrorDistZoomLow.pdf", width = 17, height = 10)
par(mfrow = c(2, 2), mar = c(2.1, 4.1, 4.1, 1.1))
hist((tsp - coef(sp.t0)[1])/sp.t0@sigma.t, freq = FALSE, breaks = 100,
     xlim = c(-5, -2), ylim = c(0, 0.1), main = "")
curve(dnorm(x, 0, 1), add = TRUE, col = "blue", lwd = 3)
text(-5, 0.09, "Standard Normal", adj = 0, cex = 1.5)
box()
par(mar = c(2.1, 3.1, 4.1, 2.1))
hist((tsp - coef(sp.t2)[1])/sp.t2@sigma.t, freq = FALSE, breaks = 100,
     xlim = c(-5, -2),
     ylim = c(0, 0.1), main = "", xlab = "Error Distribution")
curve(dstd(x, 0, 1, 10), add = TRUE, col = "blue", lwd = 3)
text(-5, 0.09, "t (10)", adj = 0, cex = 1.5)
box()
par(mar = c(5.1, 4.1, 1.1, 1.1))
hist((tsp - coef(sp.t1)[1])/sp.t1@sigma.t, freq = FALSE, breaks = 100,
     xlim = c(-5, -2),
     ylim = c(0, 0.1), main = "", ylab = "", xlab = "")
curve(dged(x, 0, 1, 1.639), add = TRUE, col = "blue", lwd = 3)
text(-5, 0.09, "Generalised Error Distribution (1.639)", adj = 0, cex = 1.5)
box()
par(mar = c(5.1, 3.1, 1.1, 2.1))
hist((tsp - coef(sp.t0)[1])/sp.sigmat, freq = FALSE, breaks = 100,
     xlim = c(-5, -2), ylim = c(0, 0.1), main = "",
     xlab = "Error Distribution")
curve(sp.mg$mix$pr[1] * dnorm(x, 0, sp.mg$mix$pt[1]) +
      sp.mg$mix$pr[2] * dnorm(x, 0, sp.mg$mix$pt[2]),
      add = TRUE, col = "blue", lwd = 3)
text(-5, 0.09, "Scale Normal Mixture", adj = 0, cex = 1.5)
box()
dev.off()


## Individual components
pdf(file = "spComp.pdf", width = 12)
curve(sp.mg$mix$pr[1] * dnorm(x, 0, sp.mg$mix$pt[1]) +
      sp.mg$mix$pr[2] * dnorm(x, 0, sp.mg$mix$pt[2]),
      col = "blue", lwd = 3, ylab = "Density", -4, 4)
curve((-0.02 + sp.mg$mix$pr[1]) * dnorm(x, 0, sp.mg$mix$pt[1]),
      add = TRUE, col = "lightblue", lwd = 3, lty = 2)
curve(sp.mg$mix$pr[2] * dnorm(x, 0, sp.mg$mix$pt[2]),
      add = TRUE, col = "lightblue", lwd = 3, lty = 2)
curve((0.01 + sp.mg$mix$pr[3]) * dnorm(x, 0, sp.mg$mix$pt[3]),
      add = TRUE, col = "lightblue", lwd = 3, lty = 2)
curve((0.01 + sp.mg$mix$pr[4]) * dnorm(x, 0, sp.mg$mix$pt[4]),
      add = TRUE, col = "lightblue", lwd = 3, lty = 2)
legend("topleft", legend = c("Scale Normal Mixture", "Component Density"),
       lty = c(1, 2), lwd = 3, col = c("blue", "lightblue"),
       bty = "n")
exp1 <- expression(paste(pi[1] ,"= 70.9%  ", theta[1],
    "= 0.71", sep = ""))
text(3, 0.475, exp1, adj = 0)
exp2 <- expression(paste(pi[2] ,"= 29.1%  ", theta[2],
    "= 1.42", sep = ""))
text(3, 0.45, exp2, adj = 0)
dev.off()


######################################################################
## Tests for Rcpp
######################################################################
