######################################################################
## Garch modeling from Sumhway and Stoffer
######################################################################

## At Home
load("c:/Users/user/Dropbox/Uni Work/Masters Thesis/Codes/State Space Model/tsa3.rda")

load("c:/Users/user/Dropbox/Uni Work/Masters THesis/Codes/Constraint Newton Method/cnm.R")

## At Work
#load("~/Dropbox/Uni Work/Masters Thesis/Codes/State Space Model/tsa3.rda")

## Have a look at the log gnp data and also fit an AR(1) process to
## remove the mean
gnpgr <- diff(log(gnp))
sarima(gnpgr, 1, 0, 0)
acf2(innov^2, 24)

## Fit the AR(1)-ARCH(1) model to the GNP data
library(fGarch)
gnp.garch <- garchFit(~arma(1, 0) + garch(1, 0), gnpgr)
summary(gnp.garch)

## Fit the GARCH(1, 1) model to the NYSE data
nyse.garch <- garchFit(~garch(1, 1), nyse)
summary(nyse.garch)

u <- nyse.garch@sigma.t
plot(window(nyse, start = 900, end = 1000),
     ylim = c(-.22, .2), ylab = "NYSE Returns")
lines(window(nyse - 2 * u, start = 900, end = 1000), lty = 2, col = "blue")
lines(window(nyse + 2 * u, start = 900, end = 1000), lty = 2, col = "blue")

######################################################################
## fGarch
######################################################################

## garchSpec -
    #Use default parameters beside alpha:
spec <- garchSpec(model = list(alpha = c(0.05, 0.05)))
spec
coef(spec)

## garchSim -
   # Simulate an univariate "timeSeries" series
x <- garchSim(spec, n = 200)

## garchFit -
fit <- garchFit( ~ garch(1, 1), data = x)

#####
## Swiss Pension
x <- as.timeSeries(data(LPP2005REC))

(fit <- garchFit(LPP40 ~ garch(1, 1),
                data = x, trace = FALSE, cond.dist = "norm"))

(fit <- garchFit(LPP40 ~ garch(1, 1),
                data = x, trace = FALSE, cond.dist = "snorm"))



(fit <- garchFit(LPP40 ~ garch(1, 1),
                data = x[-377, ], trace = FALSE))



gll <- double()
for(i in 10:nrow(x)){
    gll[i - 1] <- garchFit(LPP40 ~ garch(1, 1),
                       data = x[1:i, ], trace = FALSE)@fit$llh/
                           garchFit(LPP40 ~ garch(1, 1),
                                    data = x[1:(i - 1), ],
                                    trace = FALSE)@fit$llh
}






plot(x[, 8])
lines(as.timeSeries(fitted(fit)), col = "red", lty = 2)

plot(fit, which = c(1:13))

## sged -
par(mfrow = c(2, 2))
set.seed(1953)
r = rsged(n = 1000)
plot(r, type = "l", main = "sged", col = "steelblue")

# Plot empirical density and compare with true density:
hist(r, n = 25, probability = TRUE, border = "white", col = "steelblue")
box()
x = seq(min(r), max(r), length = 201)
lines(x, dsged(x), lwd = 2)

# Plot df and compare with true df:
plot(sort(r), (1:1000/1000), main = "Probability", col = "steelblue",
ylab = "Probability")
lines(x, psged(x), lwd = 2)

# Compute quantiles:
round(qsged(psged(q = seq(-1, 5, by = 1))), digits = 6)
## sgedFit -
sgedFit(r)

## Not run:
## sgedSlider -
if (require(tcltk)) {
sgedSlider("dist")
sgedSlider("rand")
}
## End(Not run)



######################################################################
## mgarch class for mixture density of the GARCH model
######################################################################


## Estimation for Garch(1, 1) only, we are ignoring the mean (mu) at
## the moment but will be one thing that will be implemented

## TODO:
# (1) To include the mean in the function.

# (2) Obtain the correct inital values for both a_t and sigma_t for
# thecalculation of both sigma_t and the db1


logd.mgarch <- function(x, beta, pt, which, eps = 1e-10){
    ## Initialise parameters
    T <- length(x)
    lpt <- length(pt)
    dl <- vector("list", 4)
    names(dl) = c("ld", "db1", "dt1", "dt2")
    ## Initiate the conditional variance
    sigma <- double()
    #sigma[1] <- x[1]^2 ## Need to double check this
    fg <- fgarch(data = x)
    #sigma[1] <- nyse.fgarch@sigma.t[1]^2
    #for(i in 2:T){
    #    sigma[i] <- beta[1] +
    #        beta[2] * x[i - 1]^2 + beta[3] * sigma[i - 1]
    #}
    gamma <- (x - coef(fg)[1])/fg@sigma.t
    ## Calculate the log density
    if(which[1] == 1){
        dl$ld <- c()
        ## This section can be improved
        for(i in 1:lpt){
        dl$ld <- cbind(dl$ld,
                       ifelse(!is.null(pt[i]),
                              dnorm(gamma, 0, pt[i], log = TRUE),
                              0))
    }
    }
    dl$db1
    ## Check this
    ## (1) Check whether the lag(bx, bsigma) are specified correctly
    ## (2) Check whether the equation are solved correctly
    bx <- c(x[1], x[-T])
    bsigma <- c(sigma[1], sigma[-T])
    dl$db1 <- array(0, dim = c(T, lpt, 2))
    if(which[2] == 1){
        dl$db1[,, 1] <- matrix(rep((bx * (x^2 - 1))/
                                          (2 * sigma^2), lpt), nc = lpt)
        dl$db1[,, 1] <- matrix(rep((bsigma * (x^2 - 1))/
                                          (2 * sigma^2), lpt), nc = lpt)
    }
    ## Calculate the first order derivative with respect to theta
    dl$dt1 <- double()
    if(which[3] == 1){
        for(j in 1:lpt){
            dl$dt1 <- cbind(dl$dt1,
                            (gamma^2 - 2 *pt[j])/(2 * pt[j]^2))
        }
    }
    ## Calculate the second order derivative with respect to theta
    dl$dt2 <- double()
    if(which[4] == 1){
        for(k in 1:lpt){
            dl$dt2 <- cbind(dl$dt2,
                            (pt[k] - 2 * gamma^2)/(2 * pt[k]^3))
        }
    }
    dl
}

## New logd.mgarch based on fgarch

logd.mgarch <- function(x, beta, pt, which){
    fg <- garchFit(data = as.numeric(x))
    gammat <- (x - coef(fg)[1])/fg@sigma.t
    dl <- vector("list", length = 4)
    names(dl) <- c("ld", "db1", "dt1", "dt2")
    if(which[1] == 1){
        dl$ld = -0.5 *
            sweep(outer(gammat^2, 1/pt, "*"), 2,
                  log(2 * pi) + log(pt), "+")
    }
    ## Check this, now there are no beta to estimate
    if(which[2] == 1){
    }
    if(which[3] == 1){
        dl$dt1 = sweep(outer(gammat^2, 1/(2 * pt^2), "*"), 2, 1/pt, "-")
    }
    if(which[4] == 1){
        dl$dt2 = sweep(outer(gammat^2, 1/(pt^3), "*"), 2, 1/(2 * pt^2), "-")
    }
    dl
}


## Rewrite the log-density and the key function as revised on 27th
## July 2011

logd.mgarch <- function(xt, beta, pt, which){
    T <- length(xt)
    lpt <- length(pt)
    lb <- length(beta)
    dl <- vector("list", length = 5)
    names(dl) <- c("ld", "db1", "dt1", "dt2", "sigma")
    #i.sigma <- sd(xt)
    sigma <- double() ## sigma here stands for the conditional variance
    sigma[1] <- var(xt) ## satisfactory initial value but not ideal
    for(i in 2:T){
        sigma[i] <- beta[1] +
            beta[2] * sigma[i - 1] + beta[3] * xt[i - 1]^2
    }
    #sigma <- sqrt(sigma[-1]) ## Remove the initial value of sigma
    sigma <- sqrt(sigma)
    dl$sigma <- sigma
    if(which[1] == 1){
        dl$ld <- -0.5 * (log(2 * pi) +
                         sweep(sweep(outer(xt^2/sigma^2, 1/pt, "*"),
                             2, log(pt), "+"), 1, log(sigma^2), "+"))
    }
    ## Will need to check how to obtain the initial values of x_0 and
    ## sigma_0
    lxt <- c(mean(xt), xt[-T])
    lsigma <- c((sigma[1] - beta[1] - beta[3] * mean(xt))/beta[2],
                sigma[-T])
    ## Need to change sigma_t to sigma_t-1
    if(which[2] == 1){
        dl$db1 <- sweep(array(outer(-xt^2, pt, "+")/
                        outer(-sigma^2, 2 * pt, "+"),
                        dim = c(T, lpt, lb)),
                        c(1, 3), c(rep(1, T), lsigma^2, lxt^2), "*")
    }
    if(which[3] == 1){
        dl$dt1 <- sweep(outer(xt^2/(2 * sigma^2), 1/(pt^2), "*"),
                        2, -0.5 * pt, "+")
    }
    if(which[4] == 1){
        dl$dt2 <- sweep(outer(xt^2/sigma^2, 1/(pt^3), "*"),
                        2, -0.5 * pt^2, "+")
    }
    dl
}

## Fit a garch
fg <- garchFit(data = nyse)

testFit <- logd.mgarch(mnyse - coef(fg)[1], beta = coef(fg)[c(2, 4, 3)],
                       pt = seq(1, 10, length = 100),
                       which = c(1, 1, 1, 1))
str(testFit)

testll <- apply(testFit$ld, 2, sum)
plot(testll)
seq(1, 10, length = 100)[which.max(testll)]

## Plot the derivatives
image(testFit$ld)
image(testFit$dt1)
image(testFit$dt2)

## This shows that the likelihood is higher at extreme points
plot(testFit$ld[, 1], type = "l")
lines(testFit$ld[, 100], col = "red", lty = 2)

cnmms(mnyse)

## This shows that the function can be used to estimate the parameters
## of a normal GARCH model and thus showing the log density is
## specified correctly
check.ll <- function(beta, data){
    ll <- -sum(logd.mgarch(data - coef(fg)[1], beta, pt = 1,
                       which = c(1, 0, 0, 0))$ld)
}
optim(c(0, 0.5, 0.5), check.ll, data = mnyse)

## Fit the mixture model
cnmms(mnyse)


## Valid function
## alpha_0 > 0
## alpha_i >= 0
## beta_i >= 0

valid.mgarch <- function(x, beta){
    beta[1] > 0 &&
    all(beta[-1] >= 0)
    #all(mix$pt > 0) &&
    #all(mix$pr >= 0)
}


initial.mgarch <- function(x, beta = NULL, mix = NULL, kmax = NULL){
    if(is.null(beta)){
        beta <- coef(garchFit(data = as.numeric(x)))[c(2, 4, 3)]
        mix <- dden(seq(1, var(x), length = 100), rep(1/100, 100))
        list(beta = beta, mix = mix)
    }
}

######################################################################
## Check whether the GARCH estimation is working properly
######################################################################

garch.ll <- function(beta, x){
    T <- length(x)
    sigma <- double()
    #sigma <- fg@sigma.t
    sigma[1] <- fg@sigma.t[1]^2 ## Need to double check this
    for(i in 2:T){
        sigma[i] <- beta[1] +
            beta[2] * x[i - 1]^2 + beta[3] * sigma[i - 1]
    }
    #ll = -sum(-1/2 * (log(sigma) + x^2/(2 * sigma)))
    ll = -sum(dnorm(x, 0, sqrt(sigma), log = TRUE))
    #list(ll, sigma)
    list(ll, sigma)
}

#fg <- garchFit(data = nyse)
fgcoef <- coef(fg)
plot(fg@sigma.t, type = "l")

mg <- garch.ll(c(fgcoef[2], fgcoef[3], fgcoef[4]), nyse)
plot(sqrt(mg[[2]]), type = "l")

## This shows that the sigma is estimated correctly, however can be
## improved
plot(fg@sigma.t, type = "l")
lines(sqrt(mg[[2]]), col = "red", lty = 2)

plot(fg@sigma.t - sqrt(mg[[2]]), type = "l")

fg@fit$llh
mg[[1]]
######################################################################
## The Log-likelihood and the conditional variance are very similar to
## those estimated. However, the estimation can still be improved.
######################################################################

## Now lets check the use of the mgarch class
mnyse <- nyse
class(mnyse) <- "mgarch"

Mycnmms <- function(x=rcvp2(), init=NULL, maxit=1000,
                  model=c("spmle","npmle"),
                  tol=1e-10, grid=100, kmax=Inf,
                  plot=c("null", "gradient", "prob","dden"),
                  plotorder=0, verb=0, llt=NULL) {
    plot = match.arg(plot)
    model = match.arg(model)
    k = length(x)
    if(kmax == Inf) init = initial.snpmle(x, init)
    else init = initial.snpmle(x, init, kmax=kmax)
    beta = init$beta
    nb = length(beta)
    mix = init$mix
    ll1 = -Inf
    convergence = 1
    for(i in 1:maxit) {
        l = logd(x, beta, mix$pt, which=c(1,0,0,0))$ld
        ma = apply(l, 1, max)
        dmix = drop(exp(l - ma) %*% mix$pr) + 1e-100
        switch(plot,
               "gradient" = plotgrad(x, beta, mix, ma,
                pch=19, order=plotorder),
               "prob" = plot(x, mix, beta),
               "dden" = plot(mix) )
        if(plot == "gradient") points(x$mi, rep(0,length(x$mi)),
           pch="|", cex=.5)
    if(length(mix$pt) < kmax) {
      rth = range(x, beta)
      gridpoints = seq(rth[1], rth[2], length=grid)
      g = maxgrad(x, beta, dmix, ma, grid=gridpoints, tol=-Inf)
      # g = maxgrad2(x, beta, dmix, ma, mix$pt, tol=-Inf)
      # if(plot=="gradient") points(g$pt, g$grad, pch=20, col="blue")
      gradient = max(g$grad)
      kpt = min(kmax - length(mix$pt), length(g$pt))
      jpt = order(g$grad, decreasing=TRUE)
      mix = dden(c(mix$pt,g$pt[jpt][1:kpt]), c(mix$pr,rep(0,kpt)))
  }
        lpt = logd(x, beta, mix$pt, which=c(1,0,0,0))$ld
        dpt = pmin(exp(lpt - ma), 1e100)
        a = cbind(dpt/dmix - drop(rep(2,k)))
        r = nnls(rbind(a, rep(1,length(mix$pt))), c(rep(0,nrow(a)),1))
        sol = r$x / sum(r$x)
        r = lsch(mix, beta, dden(mix$pt,sol), beta, x, which=c(1,0,0))
        mix = collapse.snpmle(r$mix, beta, x)
        r = switch(model,
        spmle = bfgs(mix, beta, x, which=c(1,1,1)),
        npmle = bfgs(mix, beta, x, which=c(1,1,0))  )
        if(r$conv == 3) {convergence = r$conv; break}
    # print(r$num.iter)
        beta = r$beta
        mix = r$mix
        if(is.null(llt))
        {if(r$ll >= ll1 && r$ll <= ll1 + tol) {convergence = 0; break}}
        else {
            if(r$ll >= llt) {convergence = 0; break}
            else if(r$ll >= ll1 && r$ll <= ll1 + 1e-16) {convergence = 1; break}
        }
        ll1 = r$ll
        print.snpmle(verb, x, mix, beta, gradient)
    }
    list(mix=mix, beta=beta, num.iterations=i,
         ll=r$ll, grad=r$grad,
                                        # max.gradient=gradient,
         convergence=convergence)
}


Mycnmms(mnyse)


grad(mnyse, beta = mybeta, dmix = mydmix, ma = myma, pt = c(1:10)/100)

maxgrad(mnyse, beta = mybeta, dmix = mydmix, ma = myma)

grid=100
tol=-Inf
maxit=100

  if( length(grid) == 1 ) {
    rth = range(mnyse, mybeta)
    grid = seq(rth[1], rth[2], length=grid)
  }


#grid <- grid[grid > 0]
np = length(grid)

#grid <- seq(0.1, 1, length = 100)
dg = grad(mnyse, grid, mybeta, mydmix, myma, order=1)$d1

jmax = (1:(np-1))[dg[1:(np-1)] > 0 & dg[2:np] < 0]

  if( length(jmax) < 1 ) return
  pt = (grid[jmax] + grid[jmax+1]) * .5
  left = grid[jmax]
  right = grid[jmax+1]
  if(length(pt) != 0) {
    pt.old = left
    d1.old = grad(mnyse, left, mybeta, mydmix, myma, order=1)$d1
    d2 = rep(-1, length(pt))  # or d2 = rep(1, length(pt))
    for( i in 1:maxit ) {
      d1 = grad(mnyse, pt, mybeta, mydmix, myma, order=1)$d1
      print(d1)
      d2t = (d1 - d1.old) / (pt - pt.old)
      jd = !is.na(d2t) & d2t < 0
      d2[jd] = d2t[jd]
      left[d1>0] = pt[d1>0]
      right[d1<0] = pt[d1<0]
      pt.old = pt
      d1.old = d1
      pt = pt - d1 / d2
      j = is.na(pt) | pt < left | pt > right
      pt[j] = (left[j] + right[j]) * .5
      # print(pt)
      if( max(abs(pt - pt.old)) <= 1e-14 * diff(range(grid))) break
    }
  }
  else i = 0
  # print(i)
  if(dg[np] >= 0) pt = c(grid[np], pt)
  if(dg[1] <= 0) pt = c(grid[1], pt)
  if(length(pt) == 0) stop("no new support point found") # should not happen
  g = grad(mnyse, pt, mybeta, mydmix, myma, order=0)$d0
  names(pt) = names(g) = NULL
  j = g >= tol
  list(pt=pt[j], grad=g[j], num.iterations=i)



grad <- function(x, pt, beta, dmix, ma, order=0) {
  if(is.dden(dmix)) {
    l = logd(x, beta, dmix$pt, which=c(1,0,0,0))$ld
    ma = apply(l, 1, max)
    dmix = drop(exp(l - ma) %*% dmix$pr) + 1e-100
  }
  g = vector("list", length(order))
  names(g) = paste("d", order, sep="")
  which = c(1,0,0,0)
  if(any(order >= 1)) which[3:max(order+2)] = 1
  dl = logd(x, beta, pt, which=which)
  s = pmin(exp(dl$ld - ma), 1e100) / dmix
  if(0 %in% order) g$d0 = colSums(s) - length(x)
  if(1 %in% order) g$d1 = colSums(s * dl$dt1)
  if(2 %in% order) g$d2 = colSums(s * (dl$dt1 * dl$dt1 + dl$dt2))
  g
}



pdf(file = "gradient.pdf")
cnm(plot = "gradient")
graphics.off()
system("open gradient.pdf")


## Check the distribution of the nyse with respective conditional
## distribution

plot(window(nyse, 900, 950), type = "b", ylim = c(-0.3, 0.2))
lines(window(nyse - 2 * fg@sigma.t, 900, 950), lty = 2, col = 4)
lines(window(nyse + 2 * fg@sigma.t, 900, 950), lty = 2, col = 4)


######################################################################
## Rewrite the maxgrad function to fix the grid
######################################################################


mybeta <- coef(fg)[c(2, 4, 3)]
myma <- apply(testFit$ld, 1, max)
mydmix <- drop(exp(testFit$ld - myma) %*%
               initial.mgarch(nyse)$mix$pr) + 1e-100

grid <- seq(1e-7, max(nyse)/sd(nyse), length = 100)
dg = grad(mnyse, grid, mybeta, mydmix, myma, order=1)$d1

jmax = (1:(np-1))[dg[1:(np-1)] > 0 & dg[2:np] < 0]

maxgrad(mnyse, initial.mgarch(mnyse)$beta, initial.mgarch(mnyse)$mix, myma)

maxgrad <- function(x, beta, dmix, ma, grid=100, tol=-Inf, maxit=100) {
    if(length(grid) == 1){
        grid <- seq(1e-7, max(x), length = grid)
    }
  np = length(grid)
  dg = grad(x, grid, beta, dmix, ma, order=1)$d1
  jmax = (1:(np-1))[dg[1:(np-1)] > 0 & dg[2:np] < 0]
  if( length(jmax) < 1 ) return
  pt = (grid[jmax] + grid[jmax+1]) * .5
  left = grid[jmax]
  right = grid[jmax+1]
  if(length(pt) != 0) {
    pt.old = left
    d1.old = grad(x, left, beta, dmix, ma, order=1)$d1
    d2 = rep(-1, length(pt))  # or d2 = rep(1, length(pt))
    for( i in 1:maxit ) {
      d1 = grad(x, pt, beta, dmix, ma, order=1)$d1
      print(d1)
      d2t = (d1 - d1.old) / (pt - pt.old)
      jd = !is.na(d2t) & d2t < 0
      d2[jd] = d2t[jd]
      left[d1>0] = pt[d1>0]
      right[d1<0] = pt[d1<0]
      pt.old = pt
      d1.old = d1
      pt = pt - d1 / d2
      j = is.na(pt) | pt < left | pt > right
      pt[j] = (left[j] + right[j]) * .5
      # print(pt)
      if( max(abs(pt - pt.old)) <= 1e-14 * diff(range(grid))) break
    }
  }
  else i = 0
  # print(i)
  if(dg[np] >= 0) pt = c(grid[np], pt)
  if(dg[1] <= 0) pt = c(grid[1], pt)
  if(length(pt) == 0) stop("no new support point found") # should not happen
  g = grad(x, pt, beta, dmix, ma, order=0)$d0
  names(pt) = names(g) = NULL
  j = g >= tol
  list(pt=pt[j], grad=g[j], num.iterations=i)
}


cnmms <- function(x=rcvp2(), init=NULL, maxit=1000,
                  model=c("spmle","npmle"),
                  tol=1e-10, grid=100, kmax=Inf,
                  plot=c("null", "gradient", "prob","dden"),
                  plotorder=0, verb=0, llt=NULL) {
    plot = match.arg(plot)
    model = match.arg(model)
    k = length(x)
    if(kmax == Inf) init = initial.snpmle(x, init)
    else init = initial.snpmle(x, init, kmax=kmax)
    beta = init$beta
    nb = length(beta)
    mix = init$mix
    ll1 = -Inf
    convergence = 1
    for(i in 1:maxit) {
        l = logd(x, beta, mix$pt, which=c(1,0,0,0))$ld
        ma = apply(l, 1, max)
        dmix = drop(exp(l - ma) %*% mix$pr) + 1e-100
        switch(plot,
               "gradient" = plotgrad(x, beta, mix, ma,
                pch=19, order=plotorder),
               "prob" = plot(x, mix, beta),
               "dden" = plot(mix) )
        #if(plot == "gradient") points(x$mi, rep(0,length(x$mi)),
         #  pch="|", cex=.5)
    if(length(mix$pt) < kmax) {
      gridpoints = seq(1e-7, max(x), length = grid)
      g = maxgrad(x, beta, dmix, ma, grid=gridpoints, tol=-Inf)
      # g = maxgrad2(x, beta, dmix, ma, mix$pt, tol=-Inf)
      # if(plot=="gradient") points(g$pt, g$grad, pch=20, col="blue")
      gradient = max(g$grad)
      kpt = min(kmax - length(mix$pt), length(g$pt))
      jpt = order(g$grad, decreasing=TRUE)
      mix = dden(c(mix$pt,g$pt[jpt][1:kpt]), c(mix$pr,rep(0,kpt)))
  }
        lpt = logd(x, beta, mix$pt, which=c(1,0,0,0))$ld
        dpt = pmin(exp(lpt - ma), 1e100)
        a = cbind(dpt/dmix - drop(rep(2,k)))
        r = nnls(rbind(a, rep(1,length(mix$pt))), c(rep(0,nrow(a)),1))
        sol = r$x / sum(r$x)
        r = lsch(mix, beta, dden(mix$pt,sol), beta, x, which=c(1,0,0))
        mix = collapse.snpmle(r$mix, beta, x)
        r = switch(model,
        spmle = bfgs(mix, beta, x, which=c(1,1,1)),
        npmle = bfgs(mix, beta, x, which=c(1,1,0))  )
        if(r$conv == 3) {convergence = r$conv; break}
    # print(r$num.iter)
        beta = r$beta
        mix = r$mix
        if(is.null(llt))
        {if(r$ll >= ll1 && r$ll <= ll1 + tol) {convergence = 0; break}}
        else {
            if(r$ll >= llt) {convergence = 0; break}
            else if(r$ll >= ll1 && r$ll <= ll1 + 1e-16) {convergence = 1; break}
        }
        ll1 = r$ll
        print.snpmle(verb, x, mix, beta, gradient)
    }
    list(mix=mix, beta=beta, num.iterations=i,
         ll=r$ll, grad=r$grad,
                                        # max.gradient=gradient,
         convergence=convergence)
}

cnmms(mnyse, plot = "gradient")


sigma <- double() ## sigma here stands for the conditional variance

sigma[1] <- var(nyse) ## satisfactory initial value but not ideal

for(i in 2:2000){
    sigma[i] <- 0.2664668 +
        0.5002002 * sigma[i - 1] + 0.5495123 * mnyse[i - 1]^2
    }

plot(nyse)

lines(nyse + 2 * sqrt(sigma), col = "red", lty = 2)
lines(nyse - 2 * sqrt(sigma), col = "red", lty = 2)

lines(0.994814216 * qnorm(0.95, 0, sigma * 0.0001575801) +
    0.005185784 * qnorm(0.95, 0, sigma * 0.2736295718), col = "blue")

lines(0.994814216 * qnorm(0.05, 0, sigma * 0.0001575801) +
    0.005185784 * qnorm(0.05, 0, sigma * 0.2736295718), col = "blue")



$mix
               pt          pr
[1,] 0.0001575801 0.994814216
[2,] 0.2736295718 0.005185784

$beta
[1] 0.2664668 0.5495123 0.5002002

$num.iterations
[1] 12

$ll
[1] 6633.59

$grad
[1] -3.576588e-10  4.559455e+06  3.959323e-02 -5.408609e+01 -3.233530e+01
[6] -3.060619e-02

$convergence
[1] 0
